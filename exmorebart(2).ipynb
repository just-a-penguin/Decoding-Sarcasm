{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9505548,"sourceType":"datasetVersion","datasetId":5785426},{"sourceId":9505557,"sourceType":"datasetVersion","datasetId":5785435},{"sourceId":9505577,"sourceType":"datasetVersion","datasetId":5785449},{"sourceId":9508912,"sourceType":"datasetVersion","datasetId":5787842},{"sourceId":9508955,"sourceType":"datasetVersion","datasetId":5787876}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install transformers\n# !pip install pytorch_lightning","metadata":{"execution":{"iopub.status.busy":"2024-09-29T11:47:56.411624Z","iopub.execute_input":"2024-09-29T11:47:56.412539Z","iopub.status.idle":"2024-09-29T11:47:56.417268Z","shell.execute_reply.started":"2024-09-29T11:47:56.412497Z","shell.execute_reply":"2024-09-29T11:47:56.416316Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import transformers\nfrom torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\nimport pandas as pd\nimport numpy as np\n\nimport torch.nn.functional as F\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning import loggers as pl_loggers\n\nimport math\nimport random\nimport re\nimport argparse\nimport nltk\nimport time\nfrom tqdm import tqdm\nimport os\nimport pickle\nimport copy\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:26.728311Z","iopub.execute_input":"2024-09-29T13:09:26.728841Z","iopub.status.idle":"2024-09-29T13:09:37.579420Z","shell.execute_reply.started":"2024-09-29T13:09:26.728803Z","shell.execute_reply":"2024-09-29T13:09:37.578422Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndevice\nprint(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:37.580886Z","iopub.execute_input":"2024-09-29T13:09:37.581337Z","iopub.status.idle":"2024-09-29T13:09:37.619810Z","shell.execute_reply.started":"2024-09-29T13:09:37.581303Z","shell.execute_reply":"2024-09-29T13:09:37.618894Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"path_to_images = '/kaggle/input/exmoreimages/images'\n\npath_to_train = '/kaggle/input/filedataset/train_df.tsv'\n\npath_to_val = '/kaggle/input/filedataset/val_df.tsv'\n\npath_to_test = '/kaggle/input/filedataset/test_df.tsv'\n\npath_to_save_model = ''","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:40.348100Z","iopub.execute_input":"2024-09-29T13:09:40.348502Z","iopub.status.idle":"2024-09-29T13:09:40.353548Z","shell.execute_reply.started":"2024-09-29T13:09:40.348462Z","shell.execute_reply":"2024-09-29T13:09:40.352424Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"class MSEDataset(Dataset):\n    def __init__(self, path_to_data_df, path_to_images, tokenizer, image_transform):\n        self.data = pd.read_csv(path_to_data_df, sep='\\t', names=['pid', 'text', 'explanation'])\n        self.path_to_images = path_to_images\n        self.tokenizer = tokenizer\n        self.image_transform = image_transform\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx, :]\n\n        pid_i = row['pid']\n        src_text = row['text']\n        target_text = row['explanation']\n\n        max_length = 256\n        encoded_dict = tokenizer(\n            src_text,\n            max_length=max_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors='pt',\n            add_prefix_space = True\n        )\n        src_ids = encoded_dict['input_ids'][0]\n        src_mask = encoded_dict['attention_mask'][0]\n\n        image_path = os.path.join(self.path_to_images, pid_i+'.jpg')\n        img = np.array(Image.open(image_path).convert('RGB'))\n        img_inp = self.image_transform(img)\n        \n\n        encoded_dict = tokenizer(\n          target_text,\n          max_length=max_length,\n          padding=\"max_length\",\n          truncation=True,\n          return_tensors='pt',\n          add_prefix_space = True\n        )\n\n        target_ids = encoded_dict['input_ids'][0]\n\n        sample = {\n            \"input_ids\": src_ids,\n            \"attention_mask\": src_mask,\n            \"input_image\": img_inp,\n            \"target_ids\": target_ids,\n        }\n        return sample\n    \n    def __len__(self):\n        return self.data.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:41.279055Z","iopub.execute_input":"2024-09-29T13:09:41.279971Z","iopub.status.idle":"2024-09-29T13:09:41.290105Z","shell.execute_reply.started":"2024-09-29T13:09:41.279929Z","shell.execute_reply":"2024-09-29T13:09:41.289009Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class MSEDataModule(pl.LightningDataModule):\n    def __init__(self, path_to_train_df, path_to_val_df, path_to_test_df, path_to_images, tokenizer, image_transform, batch_size=16):\n        super(MSEDataModule, self).__init__()\n        self.path_to_train_df = path_to_train_df\n        self.path_to_val_df = path_to_val_df\n        self.path_to_test_df = path_to_test_df\n        self.path_to_images = path_to_images\n        self.batch_size = batch_size\n        self.tokenizer = tokenizer\n        self.image_transform = image_transform\n  \n    def setup(self, stage=None):\n        self.train_dataset = MSEDataset(self.path_to_train_df, self.path_to_images, self.tokenizer, self.image_transform)\n        self.val_dataset = MSEDataset(self.path_to_val_df, self.path_to_images, self.tokenizer, self.image_transform)\n        self.test_dataset = MSEDataset(self.path_to_test_df, self.path_to_images, self.tokenizer, self.image_transform)\n  \n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, sampler = RandomSampler(self.train_dataset), batch_size = self.batch_size)\n  \n    def val_dataloader(self):\n        return DataLoader(self.val_dataset, batch_size = self.batch_size)\n  \n    def test_dataloader(self):\n        return DataLoader(self.test_dataset, batch_size = 1)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:42.960736Z","iopub.execute_input":"2024-09-29T13:09:42.961371Z","iopub.status.idle":"2024-09-29T13:09:42.970400Z","shell.execute_reply.started":"2024-09-29T13:09:42.961329Z","shell.execute_reply":"2024-09-29T13:09:42.969414Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Model for Multimodal Sarcasm Detection Pre-training","metadata":{}},{"cell_type":"code","source":"from transformers import BartTokenizer, BartForConditionalGeneration, BartModel, AdamW, BartConfig, BartPretrainedModel, PreTrainedModel\n\nfrom dataclasses import dataclass\nfrom typing import Optional, Tuple, List\nfrom transformers.file_utils import ModelOutput\n\nfrom typing import Any, Callable, Dict, Iterable, List, Optional, Tuple\n\nimport torch\nfrom torch.nn import functional as F\n\nfrom transformers.file_utils import ModelOutput\nfrom transformers.generation.beam_search import BeamScorer, BeamSearchScorer\nfrom transformers.generation.logits_process import (\n    HammingDiversityLogitsProcessor,\n    LogitsProcessorList,\n    MinLengthLogitsProcessor,\n    NoBadWordsLogitsProcessor,\n    NoRepeatNGramLogitsProcessor,\n    PrefixConstrainedLogitsProcessor,\n    RepetitionPenaltyLogitsProcessor,\n    TemperatureLogitsWarper,\n    TopKLogitsWarper,\n    TopPLogitsWarper,\n)\n\nfrom transformers.utils import logging\n\n\nlogger = logging.get_logger(__name__)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:43.590423Z","iopub.execute_input":"2024-09-29T13:09:43.591169Z","iopub.status.idle":"2024-09-29T13:09:44.065907Z","shell.execute_reply.started":"2024-09-29T13:09:43.591130Z","shell.execute_reply":"2024-09-29T13:09:44.065132Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass SequenceClassifierOutput(ModelOutput):\n    loss: Optional[torch.FloatTensor] = None\n    logits: torch.FloatTensor = None\n    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n    attentions: Optional[Tuple[torch.FloatTensor]] = None\n\ndef getClones(module, N):\n    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n\ndef attention(q, k, v, d_k, mask=None, dropout=None):\n    scores = torch.matmul(q, k.transpose(-2, -1)) /  math.sqrt(d_k)\n    if mask is not None:\n        mask = mask.unsqueeze(1)\n        scores = scores.masked_fill(mask == 0, -1e9)\n    scores = F.softmax(scores, dim=-1)\n    \n    if dropout is not None:\n        scores = dropout(scores)\n        \n    output = torch.matmul(scores, v)\n    return output\n\nclass CrossmodalMultiHeadAttention(nn.Module):\n    def __init__(self, heads, d_model, img_model=512, dropout = 0.1):\n        super().__init__()\n        self.d_model = d_model\n        self.d_k = d_model // heads\n        self.h = heads\n        \n        self.q_linear = nn.Linear(d_model, d_model)\n        self.v_linear = nn.Linear(img_model, d_model)\n        self.k_linear = nn.Linear(img_model, d_model)\n        self.dropout = nn.Dropout(dropout)\n        self.out = nn.Linear(d_model, d_model)\n    \n    def forward(self, q, k, v, mask=None):\n        \n        bs = q.size(0)\n        \n        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n        \n        k = k.transpose(1,2)\n        q = q.transpose(1,2)\n        v = v.transpose(1,2)\n        \n        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n        \n        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n        \n        output = self.out(concat)\n\n        return output\n\nclass FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n        super().__init__() \n        #d_ff is set as default to 2048\n        self.linear_1 = nn.Linear(d_model, d_ff)\n        self.dropout = nn.Dropout(dropout)\n        self.linear_2 = nn.Linear(d_ff, d_model)\n    \n    def forward(self, x):\n        x = self.dropout(F.relu(self.linear_1(x)))\n        x = self.linear_2(x)\n        return x\n\nclass Norm(nn.Module):\n    def __init__(self, d_model, eps = 1e-6):\n        super().__init__()\n        self.size = d_model\n        self.alpha = nn.Parameter(torch.ones(self.size))\n        self.bias = nn.Parameter(torch.zeros(self.size))\n        self.eps = eps\n    \n    def forward(self, x):\n        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n        return norm\n\nclass CrossmodalEncoderLayer(nn.Module):\n    def __init__(self, d_model, heads, img_model=512, dropout = 0.1):\n        super().__init__()\n        self.norm_1 = Norm(d_model)\n        self.norm_2 = Norm(d_model)\n        self.attn = CrossmodalMultiHeadAttention(heads, d_model, img_model=img_model)\n        self.ff = FeedForward(d_model)\n        self.dropout_1 = nn.Dropout(dropout)\n        self.dropout_2 = nn.Dropout(dropout)\n        \n    def forward(self, text_feats, img_feats, mask):\n        x = text_feats\n        x2 = self.norm_1(x)\n        x = x + self.dropout_1(self.attn(x2,img_feats,img_feats))\n        x2 = self.norm_2(x)\n        x = x + self.dropout_2(self.ff(x2))\n        return x\n\nclass CrossmodalEncoder(nn.Module):\n    def __init__(self, d_model, img_model=512, heads=4, N=1, dropout=0.1):\n        super(CrossmodalEncoder, self).__init__()\n        self.N = N\n        self.cme_layers = getClones(CrossmodalEncoderLayer(d_model, heads, img_model=img_model, dropout=dropout), N)\n        self.norm = Norm(d_model)\n    \n    def forward(self, text_feats, img_feats, mask):\n        x = text_feats\n        for i in range(self.N):\n            x = self.cme_layers[i](x, img_feats, mask)\n        return self.norm(x)\n\nclass MultimodalBartEncoder(PreTrainedModel):\n    def __init__(self, bart_encoder, bart_config, image_encoder, img_model=512, N=1, heads=4, dropout=0.1):\n        super(MultimodalBartEncoder, self).__init__(bart_config)\n        self.config = bart_config\n        self.bart_encoder = bart_encoder\n        self.image_encoder = image_encoder\n        self.N=N\n        self.img_model = img_model\n        self.cross_modal_encoder = CrossmodalEncoder(self.config.d_model, img_model=img_model, heads=heads, N=N, dropout=dropout)\n    \n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        inputs_embeds=None,\n        image_features=None,\n        output_attentions=None,\n        output_hidden_states=None,\n        return_dict=None,\n        ):\n            return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n            \n            vgg_image_features = self.image_encoder(image_features)\n            \n            vgg_image_features = vgg_image_features.permute(0, 2, 3, 1)\n            vgg_image_features = vgg_image_features.view(\n                -1, \n                vgg_image_features.size()[1]*vgg_image_features.size()[2], \n                self.img_model\n                )\n            \n            encoder_outputs = self.bart_encoder(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                inputs_embeds=inputs_embeds,\n                output_attentions=output_attentions,\n                output_hidden_states=output_hidden_states,\n                return_dict=return_dict,\n            )\n            \n            cross_modal_encoder_outputs = self.cross_modal_encoder(\n                encoder_outputs.last_hidden_state, \n                vgg_image_features,\n                attention_mask\n            )\n            \n            encoder_outputs.last_hidden_state = torch.cat((encoder_outputs.last_hidden_state, cross_modal_encoder_outputs), dim=-2)\n            return encoder_outputs\n\nclass BartClassificationHead(nn.Module):\n    \"\"\"Head for sentence-level classification tasks.\"\"\"\n    def __init__(\n        self,\n        input_dim: int,\n        inner_dim: int,\n        num_classes: int,\n        pooler_dropout: float,\n    ):\n        super().__init__()\n        self.dense = nn.Linear(input_dim, inner_dim)\n        self.dropout = nn.Dropout(p=pooler_dropout)\n        self.out_proj = nn.Linear(inner_dim, num_classes)\n\n    def forward(self, hidden_states: torch.Tensor):\n        hidden_states = self.dropout(hidden_states)\n        hidden_states = self.dense(hidden_states)\n        hidden_states = torch.tanh(hidden_states)\n        hidden_states = self.dropout(hidden_states)\n        hidden_states = self.out_proj(hidden_states)\n        return hidden_states\n\nclass BartForMultimodalSarcasmDetection(BartPretrainedModel):\n    def __init__(self, bart_model_encoder, bart_config, image_encoder, num_labels=2, dropout_rate=0.1, img_model=512, N=1, heads=4):\n        super(BartForMultimodalSarcasmDetection, self).__init__(bart_config)\n        self.config = bart_config\n        self.encoder = MultimodalBartEncoder(bart_model_encoder, bart_config, image_encoder, img_model=img_model, N=N, heads=heads, dropout=dropout_rate)\n        self.classification_head = BartClassificationHead(\n            self.config.d_model,\n            self.config.d_model,\n            num_labels,\n            dropout_rate,\n        )\n        self._init_weights(self.classification_head.dense)\n        self._init_weights(self.classification_head.out_proj)\n    \n    def get_encoder(self):\n        return self.encoder\n    \n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        past_key_values=None,\n        inputs_embeds=None,\n        image_features = None,\n        use_cache=None,\n        output_attentions=None,\n        output_hidden_states=None,\n        return_dict=None\n    ):\n        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n\n        encoder_outputs = self.encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            inputs_embeds=inputs_embeds,\n            image_features=image_features,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict,\n        )\n\n        classification_feature_vector = encoder_outputs.last_hidden_state.mean(dim=-2)\n        logits = self.classification_head(classification_feature_vector)\n        loss = None\n        return SequenceClassifierOutput(\n            loss=loss,\n            logits=logits,\n            hidden_states=encoder_outputs.last_hidden_state,\n            attentions=encoder_outputs.attentions,\n        )\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:45.023471Z","iopub.execute_input":"2024-09-29T13:09:45.024011Z","iopub.status.idle":"2024-09-29T13:09:45.086272Z","shell.execute_reply.started":"2024-09-29T13:09:45.023975Z","shell.execute_reply":"2024-09-29T13:09:45.084988Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:785: FutureWarning: The class `PretrainedBartModel` has been depreciated, please use `BartPreTrainedModel` instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pytorch Lightning model for Multimodal Sarcasm Detection Pre-training","metadata":{}},{"cell_type":"code","source":"class PyLitModel(pl.LightningModule):\n    def __init__(self, model, hparams):\n        super().__init__()\n        self.model = model\n        self.hparams.update(hparams)\n\n        if self.hparams['freeze_encoder']:\n            freeze_params(self.model.encoder.bart_encoder)\n\n        if self.hparams['freeze_embeds']:\n            self.freeze_embeds()\n    \n    def freeze_embeds(self):\n        ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n        freeze_params(self.model.bart_model_shared)\n        for d in [self.model.encoder.bart_encoder, self.model.decoder]:\n            freeze_params(d.embed_positions)\n            freeze_params(d.embed_tokens)\n\n    def forward(self, input_ids, **kwargs):\n        return self.model(input_ids, **kwargs)\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(\n            [\n                {\"params\": self.model.encoder.cross_modal_encoder.parameters(), \"lr\": self.hparams['lr']},\n                {\"params\": self.model.classification_head.parameters(), \"lr\": self.hparams['lr']},\n            ],\n        )\n        return optimizer\n\n    def training_step(self, batch, batch_idx):\n        src_ids, src_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n        image_features = batch['input_image'].to(device)\n        labels = batch['target_ids'].to(device)\n        \n        outputs = self(src_ids, attention_mask=src_mask, image_features=input_images, use_cache=False)\n        classification_logits = outputs.logits\n        \n        # The loss function\n        ce_loss = torch.nn.CrossEntropyLoss() #ignore_index=self.tokenizer.pad_token_id)\n        \n        # Calculate the loss on the un-shifted tokens\n        loss = ce_loss(classification_logits.view(-1, classification_logits.shape[-1]), labels.view(-1))\n        \n        self.log('train_cross_entropy_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return {'loss':loss}\n\n    def validation_step(self, batch, batch_idx):\n\n        src_ids = batch['input_ids'].to(device)\n        src_mask = batch['attention_mask'].to(device)\n        image_features = batch['input_image'].to(device)\n        labels = batch['target_ids'].to(device)\n                \n        outputs = self(src_ids, attention_mask=src_mask, image_features=input_images, use_cache=False)\n        classification_logits = outputs.logits\n\n        ce_loss = torch.nn.CrossEntropyLoss() #ignore_index=self.tokenizer.pad_token_id)\n        val_loss = ce_loss(classification_logits.view(-1, classification_logits.shape[-1]), labels.view(-1))\n        \n        self.log('val_cross_entropy_loss', val_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        self.log('val_f1_score', f1(F.softmax(classification_logits, dim=1), labels, num_classes=2), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return {'loss': val_loss}\n    \n    def predict(self, src_ids, src_mask, input_images):\n        src_ids = src_ids.to(device)\n        src_mask = src_mask.to(device)\n        input_images = input_images.to(device)\n\n        outputs = self(src_ids, attention_mask=src_mask, input_images=input_images, use_cache=False)\n        classification_logits = outputs.logits\n        class_probs = F.softmax(classification_logits, dim=1)\n        return torch.argmax(class_probs, dim=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:49.281006Z","iopub.execute_input":"2024-09-29T13:09:49.281929Z","iopub.status.idle":"2024-09-29T13:09:49.299898Z","shell.execute_reply.started":"2024-09-29T13:09:49.281886Z","shell.execute_reply":"2024-09-29T13:09:49.298995Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Main Model - ExMore","metadata":{}},{"cell_type":"code","source":"def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int):\n    \"\"\"\n    Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n    \"\"\"\n    prev_output_tokens = input_ids.clone()\n\n    assert pad_token_id is not None, \"self.model.config.pad_token_id has to be defined.\"\n    # replace possible -100 values in labels by `pad_token_id`\n    prev_output_tokens.masked_fill_(prev_output_tokens == -100, pad_token_id)\n\n    index_of_eos = (prev_output_tokens.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n    decoder_start_tokens = prev_output_tokens.gather(1, index_of_eos).squeeze()\n    prev_output_tokens[:, 1:] = prev_output_tokens[:, :-1].clone()\n    prev_output_tokens[:, 0] = decoder_start_tokens\n\n    return prev_output_tokens\n\n@dataclass\nclass Seq2SeqLMOutput(ModelOutput):\n    loss: Optional[torch.FloatTensor] = None\n    logits: torch.FloatTensor = None\n    past_key_values: Optional[List[torch.FloatTensor]] = None\n    decoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n    decoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n    cross_attentions: Optional[Tuple[torch.FloatTensor]] = None\n    encoder_last_hidden_state: Optional[torch.FloatTensor] = None\n    encoder_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n    encoder_attentions: Optional[Tuple[torch.FloatTensor]] = None\n    \n\nclass BartForMultimodalSarcasmExplanation(BartPretrainedModel):\n    def __init__(self, multimodal_bart_encoder_TL, bart_decoder, bart_config, bart_model_num_embs, img_model=512, N=1, heads=4):\n        super(BartForMultimodalSarcasmExplanation, self).__init__(bart_config)\n        self.config = bart_config\n        self.encoder = multimodal_bart_encoder_TL\n        self.decoder = bart_decoder\n        self.lm_head = nn.Linear(self.config.d_model, bart_model_num_embs) #, bias=False)\n        \n        self._init_weights(self.lm_head)\n    \n    def get_encoder(self):\n        return self.encoder\n    \n    def get_decoder(self):\n        return self.decoder\n    \n    def prepare_inputs_for_generation(\n        self,\n        decoder_input_ids, past=None, \n        attention_mask=None, \n        use_cache=None, \n        encoder_outputs=None, \n        image_features=None,\n        **kwargs\n    ):\n        # cut decoder_input_ids if past is used\n        if past is not None:\n            decoder_input_ids = decoder_input_ids[:, -1:]\n\n        return {\n            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n            \"encoder_outputs\": encoder_outputs,\n            \"image_features\": image_features,\n            \"past_key_values\": past,\n            \"decoder_input_ids\": decoder_input_ids,\n            \"attention_mask\": attention_mask,\n            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n        }\n    \n    #def adjust_logits_during_generation(self, logits, cur_len, max_length):\n    #    if cur_len == 1 and self.config.force_bos_token_to_be_generated:\n    #        self._force_token_id_to_be_generated(logits, self.config.bos_token_id)\n    #    elif cur_len == max_length - 1 and self.config.eos_token_id is not None:\n    #        self._force_token_id_to_be_generated(logits, self.config.eos_token_id)\n    #    return logits\n\n    @staticmethod\n    def _force_token_id_to_be_generated(scores, token_id) -> None:\n        \"\"\"force one of token_ids to be generated by setting prob of all other tokens to 0 (logprob=-float(\"inf\"))\"\"\"\n        scores[:, [x for x in range(scores.shape[1]) if x != token_id]] = -float(\"inf\")\n\n    @staticmethod\n    def _reorder_cache(past, beam_idx):\n        reordered_past = ()\n        for layer_past in past:\n            reordered_past += (tuple(past_state.index_select(0, beam_idx) for past_state in layer_past),)\n        return reordered_past\n    \n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        decoder_input_ids=None,\n        decoder_attention_mask=None,\n        encoder_outputs=None,\n        past_key_values=None,\n        inputs_embeds=None,\n        decoder_inputs_embeds=None,\n\n        image_features = None,\n        \n        use_cache=None,\n        output_attentions=None,\n        output_hidden_states=None,\n        return_dict=None\n    ):\n        use_cache = use_cache if use_cache is not None else self.config.use_cache\n        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n        if decoder_input_ids is None and decoder_inputs_embeds is None:\n            decoder_input_ids = shift_tokens_right(input_ids, self.config.pad_token_id)\n        \n        if encoder_outputs is None:\n            encoder_outputs = self.encoder(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                inputs_embeds=inputs_embeds,\n                image_features=image_features,\n                output_attentions=output_attentions,\n                output_hidden_states=output_hidden_states,\n                return_dict=return_dict,\n            )\n        \n        enc_attn_mask = torch.cat((attention_mask, attention_mask), dim=-1)\n        \n        decoder_outputs = self.decoder(\n            input_ids=decoder_input_ids,\n            attention_mask=decoder_attention_mask,\n            encoder_hidden_states=encoder_outputs.last_hidden_state,\n            encoder_attention_mask=enc_attn_mask,\n            past_key_values=past_key_values,\n            inputs_embeds=decoder_inputs_embeds,\n            use_cache=use_cache,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict\n        )\n\n        lm_logits = self.lm_head(decoder_outputs.last_hidden_state)\n        \n        masked_lm_loss = None\n        return Seq2SeqLMOutput(\n            loss=masked_lm_loss,\n            logits=lm_logits,\n            past_key_values=past_key_values,\n            decoder_hidden_states=decoder_outputs.hidden_states,\n            decoder_attentions=decoder_outputs.attentions,\n            cross_attentions=decoder_outputs.cross_attentions,\n            encoder_last_hidden_state=encoder_outputs.last_hidden_state, # also carries crossmodal_encoder_last_hidden_state concatenated.\n            encoder_hidden_states=encoder_outputs.hidden_states,\n            encoder_attentions=encoder_outputs.attentions,\n        )\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:51.342145Z","iopub.execute_input":"2024-09-29T13:09:51.342547Z","iopub.status.idle":"2024-09-29T13:09:51.366377Z","shell.execute_reply.started":"2024-09-29T13:09:51.342508Z","shell.execute_reply":"2024-09-29T13:09:51.365405Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"##  Pytorch Lightning - Main Model - ExMore","metadata":{}},{"cell_type":"code","source":"class PyLitBartForMultimodalSarcasmExplanation(pl.LightningModule):\n    def __init__(self, model, tokenizer, hparams):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.model = model\n        self.hparams.update(hparams)\n        \n        if self.hparams['freeze_image_encoder']:\n            freeze_params(self.model.encoder.image_encoder)\n        \n        if self.hparams['freeze_encoder']:\n            freeze_params(self.model.encoder.bart_encoder)\n\n        if self.hparams['freeze_embeds']:\n            self.freeze_embeds()\n  \n    def freeze_embeds(self):\n        ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n        freeze_params(self.model.bart_model_shared)\n        for d in [self.model.encoder.bart_encoder, self.model.decoder]:\n            freeze_params(d.embed_positions)\n            freeze_params(d.embed_tokens)\n\n    def forward(self, input_ids, **kwargs):\n        return self.model(input_ids, **kwargs)\n  \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(\n          [\n              {\"params\": self.model.encoder.cross_modal_encoder.parameters(), \"lr\": self.hparams['lr_finetune_cm']},\n              {\"params\": self.model.lm_head.parameters(), \"lr\": self.hparams['lr']},\n          ],\n        )\n        return optimizer\n\n    def training_step(self, batch, batch_idx):\n        \n        src_ids, src_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n        image_features = batch['input_image'].to(device)\n        tgt_ids = batch['target_ids'].to(device)\n        \n        # Shift the decoder tokens right (but NOT the tgt_ids)\n        decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n\n        # Run the model and get the logits\n        outputs = self(src_ids, attention_mask=src_mask, image_features=image_features, decoder_input_ids=decoder_input_ids, use_cache=False)\n        lm_logits = outputs.logits\n        \n        # the loss function\n        ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n        \n        # Calculate the loss on the un-shifted tokens\n        loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return {'loss':loss}\n\n    def validation_step(self, batch, batch_idx):\n        src_ids = batch['input_ids'].to(device)\n        src_mask = batch['attention_mask'].to(device)\n        image_features = batch['input_image'].to(device)\n        tgt_ids = batch['target_ids'].to(device)\n        \n        decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n\n        # Run the model and get the logits\n        outputs = self(src_ids, attention_mask=src_mask, image_features=image_features, decoder_input_ids=decoder_input_ids, use_cache=False)\n        lm_logits = outputs.logits\n\n        ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n        val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n        self.log('val_loss', val_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return {'loss': val_loss}\n  \n    # This method generates text using the BartForConditionalGeneration's generate() method\n    def generate_text(self, text, eval_beams, image_features=None, early_stopping = True, max_len = 40):\n        ''' Function to generate text '''\n        \n        model_kwargs = {\n            \"image_features\": image_features\n        }\n        generated_ids = self.model.generate(\n            text[\"input_ids\"],\n            attention_mask=text[\"attention_mask\"],\n            use_cache=True,\n            decoder_start_token_id = self.tokenizer.pad_token_id,\n            num_beams= eval_beams,\n            max_length = max_len,\n            early_stopping = early_stopping,\n            **model_kwargs,\n        )\n        return [self.tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in generated_ids]\n\ndef freeze_params(model):\n    ''' This function takes a model or its subset as input and freezes the layers for faster training\n      adapted from finetune.py '''\n    for layer in model.parameters():\n        layer.requires_grade = False","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:54.841886Z","iopub.execute_input":"2024-09-29T13:09:54.842315Z","iopub.status.idle":"2024-09-29T13:09:54.861985Z","shell.execute_reply.started":"2024-09-29T13:09:54.842273Z","shell.execute_reply":"2024-09-29T13:09:54.860918Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Load Model","metadata":{}},{"cell_type":"code","source":"def load_image_encoder():\n    vgg19model = models.vgg19(pretrained=True)\n    image_encoder = list(vgg19model.children())[0]\n    return image_encoder\n\nimage_transform = transforms.Compose([\n    transforms.ToTensor(),                               \n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n  ])","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:57.373881Z","iopub.execute_input":"2024-09-29T13:09:57.374287Z","iopub.status.idle":"2024-09-29T13:09:57.381148Z","shell.execute_reply.started":"2024-09-29T13:09:57.374248Z","shell.execute_reply":"2024-09-29T13:09:57.379891Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', add_prefix_space=True, attn_implementation=\"eager\")\n\nbart_model = BartModel.from_pretrained('facebook/bart-base', attn_implementation=\"eager\")\n\nbart_config = BartConfig.from_pretrained(\"facebook/bart-base\", return_dict=True, attn_implementation=\"eager\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:09:59.524049Z","iopub.execute_input":"2024-09-29T13:09:59.524465Z","iopub.status.idle":"2024-09-29T13:10:06.132667Z","shell.execute_reply.started":"2024-09-29T13:09:59.524425Z","shell.execute_reply":"2024-09-29T13:10:06.131742Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15ef3b54c62d48c08c2ecd21af1b8e53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c109288c26d48e0bd28bcecc14febfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8da5aacc50e14cd3acae38229ca17ee2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84b784740deb468b83676153aa805341"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daabd633467b49f79336ba8922461546"}},"metadata":{}}]},{"cell_type":"code","source":"image_encoder = load_image_encoder()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:10:06.134539Z","iopub.execute_input":"2024-09-29T13:10:06.135133Z","iopub.status.idle":"2024-09-29T13:10:10.533207Z","shell.execute_reply.started":"2024-09-29T13:10:06.135068Z","shell.execute_reply":"2024-09-29T13:10:10.532147Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n100%|██████████| 548M/548M [00:02<00:00, 212MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"hparams = {\n    'freeze_encoder': False,\n    'freeze_embeds': False,\n    'freeze_image_encoder': True,\n    'eval_beams': 4,\n    'lr_finetune_cm':1e-5, #for crossmodal encoder\n    'lr': 3e-4, #for lm_head\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:10:18.479336Z","iopub.execute_input":"2024-09-29T13:10:18.479755Z","iopub.status.idle":"2024-09-29T13:10:18.484637Z","shell.execute_reply.started":"2024-09-29T13:10:18.479712Z","shell.execute_reply":"2024-09-29T13:10:18.483677Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"bart_model_for_msd = BartForMultimodalSarcasmDetection(\n    bart_model.get_encoder(), \n    bart_config, \n    image_encoder, \n    num_labels=2,\n    dropout_rate=0.1,\n    img_model=512,\n    N=1,\n    heads=4,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:10:19.951851Z","iopub.execute_input":"2024-09-29T13:10:19.952252Z","iopub.status.idle":"2024-09-29T13:10:20.009936Z","shell.execute_reply.started":"2024-09-29T13:10:19.952213Z","shell.execute_reply":"2024-09-29T13:10:20.009111Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"msd_checkpoint_path = '/kaggle/input/checkpooijtttt/MSD_pretrained_model.ckpt'\npylit_bart_model_for_msd = PyLitModel.load_from_checkpoint(checkpoint_path=msd_checkpoint_path, \n                                      model = bart_model_for_msd, \n                                      hparams = hparams)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:10:41.127872Z","iopub.execute_input":"2024-09-29T13:10:41.128680Z","iopub.status.idle":"2024-09-29T13:10:46.526940Z","shell.execute_reply.started":"2024-09-29T13:10:41.128637Z","shell.execute_reply":"2024-09-29T13:10:46.526143Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"multimodal_bart_encoder_TL = pylit_bart_model_for_msd.model.get_encoder()\nbart_decoder = bart_model.get_decoder()\n\nbart_model_num_embs = bart_model.shared.num_embeddings","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:10:47.636238Z","iopub.execute_input":"2024-09-29T13:10:47.636624Z","iopub.status.idle":"2024-09-29T13:10:47.641297Z","shell.execute_reply.started":"2024-09-29T13:10:47.636587Z","shell.execute_reply":"2024-09-29T13:10:47.640282Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"bart_for_mse = BartForMultimodalSarcasmExplanation(multimodal_bart_encoder_TL, \n                                            bart_decoder, bart_config, \n                                            bart_model_num_embs, img_model=512, N=1, heads=4)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:10:48.556964Z","iopub.execute_input":"2024-09-29T13:10:48.557802Z","iopub.status.idle":"2024-09-29T13:10:49.160038Z","shell.execute_reply.started":"2024-09-29T13:10:48.557757Z","shell.execute_reply":"2024-09-29T13:10:49.158984Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data into the model for training\n\nmse_data = MSEDataModule(path_to_train, path_to_val, \n                         path_to_test, path_to_images, \n                         tokenizer, image_transform, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:10:50.521141Z","iopub.execute_input":"2024-09-29T13:10:50.521974Z","iopub.status.idle":"2024-09-29T13:10:50.526286Z","shell.execute_reply.started":"2024-09-29T13:10:50.521934Z","shell.execute_reply":"2024-09-29T13:10:50.525275Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Load the model from a pre-saved checkpoint or use the code below to start training from scratch\n\nmain_model = PyLitBartForMultimodalSarcasmExplanation(tokenizer = tokenizer, model = bart_for_mse, hparams = hparams)\n\n# model = PyLitBartForMultimodalSarcasmExplanation.load_from_checkpoint(checkpoint_path=\"ckpt path\",\n                                    #   tokenizer = tokenizer, model = bart_for_mse, hparams = hparams)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:10:52.701627Z","iopub.execute_input":"2024-09-29T13:10:52.702027Z","iopub.status.idle":"2024-09-29T13:10:52.707290Z","shell.execute_reply.started":"2024-09-29T13:10:52.701985Z","shell.execute_reply":"2024-09-29T13:10:52.706261Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Training the model with Pytorch Lightning","metadata":{}},{"cell_type":"code","source":"import os\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger  # Correct import\n\nckpt_dir = os.path.join(path_to_save_model, 'model_dir')\ncheckpoint = ModelCheckpoint(\n    dirpath=ckpt_dir,\n    monitor='val_loss',\n    save_top_k=15,\n    mode='min',\n    filename='{epoch}-{val_loss:.3f}'\n)\ntb_logger = TensorBoardLogger(os.path.join(ckpt_dir, 'logs/'))  # Use the correct logger\n\ntrainer = pl.Trainer(\n    logger=tb_logger,\n#     gpus=1,\n    max_epochs=125,\n    min_epochs=5,\n#     auto_lr_find=False,\n    callbacks=[checkpoint],  # Update this to use `callbacks` instead of `checkpoint_callback`\n#     progress_bar_refresh_rate=10\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:10:55.551112Z","iopub.execute_input":"2024-09-29T13:10:55.552216Z","iopub.status.idle":"2024-09-29T13:10:55.613172Z","shell.execute_reply.started":"2024-09-29T13:10:55.552159Z","shell.execute_reply":"2024-09-29T13:10:55.612423Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# import os\n# import shutil\n\n# # Path to the model directory\n# model_dir = \"/kaggle/working/model_dir\"\n\n# # Loop through the files in the directory\n# for file_name in os.listdir(model_dir):\n#     if file_name.endswith(\".ckpt\"):  # Check if the file is a checkpoint file\n#         file_path = os.path.join(model_dir, file_name)\n#         os.remove(file_path)  # Remove the checkpoint file\n\n# print(\"Checkpoint files removed. Logs are intact.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T12:50:37.412612Z","iopub.execute_input":"2024-09-29T12:50:37.412996Z","iopub.status.idle":"2024-09-29T12:50:38.578881Z","shell.execute_reply.started":"2024-09-29T12:50:37.412959Z","shell.execute_reply":"2024-09-29T12:50:38.577993Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Checkpoint files removed. Logs are intact.\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Fit the instantiated model to the data\ntrainer.fit(main_model, mse_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:11:33.439788Z","iopub.execute_input":"2024-09-29T13:11:33.440230Z","iopub.status.idle":"2024-09-29T13:11:33.444750Z","shell.execute_reply.started":"2024-09-29T13:11:33.440191Z","shell.execute_reply":"2024-09-29T13:11:33.443741Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# This is to manually save a checkpoint, although the model should automatically save checkpoints as it moves through the epochs\ntrainer.save_checkpoint(os.path.join(ckpt_dir,\"last_epoch_125.ckpt\"))","metadata":{"execution":{"iopub.status.busy":"2024-09-29T11:48:27.436289Z","iopub.execute_input":"2024-09-29T11:48:27.436635Z","iopub.status.idle":"2024-09-29T11:48:27.441882Z","shell.execute_reply.started":"2024-09-29T11:48:27.436595Z","shell.execute_reply":"2024-09-29T11:48:27.440982Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"ckpt_path = '/kaggle/input/finalcheckpoint/ExMore_model.ckpt'\nmain_model = PyLitBartForMultimodalSarcasmExplanation.load_from_checkpoint(checkpoint_path=ckpt_path,strict=False,\n                                      tokenizer = tokenizer, model = bart_for_mse, hparams = hparams)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:11:44.226276Z","iopub.execute_input":"2024-09-29T13:11:44.226687Z","iopub.status.idle":"2024-09-29T13:11:45.288047Z","shell.execute_reply.started":"2024-09-29T13:11:44.226648Z","shell.execute_reply":"2024-09-29T13:11:45.287044Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/migration/migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n","output_type":"stream"}]},{"cell_type":"code","source":"test = pd.read_csv(path_to_test, sep='\\t', header=None)\n# test = pd.read_csv(path_to_train, sep='\\t', header=None)\ntest.columns = ['pid', 'source', 'target']\npids = test.pid.tolist()\nsource = test.source.tolist()\ntarget = test.target.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:11:47.486878Z","iopub.execute_input":"2024-09-29T13:11:47.487807Z","iopub.status.idle":"2024-09-29T13:11:47.497528Z","shell.execute_reply.started":"2024-09-29T13:11:47.487762Z","shell.execute_reply":"2024-09-29T13:11:47.496631Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"main_model.to(device)\nmain_model.eval()\nprint(\"\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:11:49.426755Z","iopub.execute_input":"2024-09-29T13:11:49.427161Z","iopub.status.idle":"2024-09-29T13:11:49.890273Z","shell.execute_reply.started":"2024-09-29T13:11:49.427121Z","shell.execute_reply":"2024-09-29T13:11:49.889307Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\n\neval_beams = 4\npred = []\n\n# Wrap zip(pids, source, target) with tqdm for a progress bar\nfor pid_i, src, tgt in tqdm(zip(pids, source, target), total=len(pids), desc=\"Processing\", leave=False):\n    encoded_dict = tokenizer(\n        src,\n        max_length=256,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors='pt',\n        add_prefix_space=True\n    )\n    encoded_dict['input_ids'] = encoded_dict['input_ids'].to(device)\n    encoded_dict['attention_mask'] = encoded_dict['attention_mask'].to(device)\n\n    if type(pid_i) is not str:\n        pid_i = str(pid_i)\n\n    image_path = os.path.join(path_to_images, pid_i + '.jpg')\n    img = np.array(Image.open(image_path).convert('RGB'))\n    img_feats = image_transform(img).unsqueeze(0)\n\n    gen = main_model.generate_text(\n        encoded_dict, \n        eval_beams, \n        image_features=img_feats.to(device), \n        early_stopping=True, \n        max_len=256\n    )\n\n    pred.append(gen[0])\n    hypothesis = gen[0].split()\n    reference = tgt.split()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:13:26.168204Z","iopub.execute_input":"2024-09-29T13:13:26.168624Z","iopub.status.idle":"2024-09-29T13:15:35.426369Z","shell.execute_reply.started":"2024-09-29T13:13:26.168583Z","shell.execute_reply":"2024-09-29T13:15:35.425417Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"\nProcessing:   0%|          | 0/352 [00:00<?, ?it/s]\u001b[A\nProcessing:   0%|          | 1/352 [00:00<02:05,  2.79it/s]\u001b[A\nProcessing:   1%|          | 2/352 [00:00<01:45,  3.31it/s]\u001b[A\nProcessing:   1%|          | 3/352 [00:00<01:51,  3.13it/s]\u001b[A\nProcessing:   1%|          | 4/352 [00:01<02:15,  2.58it/s]\u001b[A\nProcessing:   1%|▏         | 5/352 [00:01<02:05,  2.77it/s]\u001b[A\nProcessing:   2%|▏         | 6/352 [00:02<01:52,  3.06it/s]\u001b[A\nProcessing:   2%|▏         | 7/352 [00:02<02:09,  2.67it/s]\u001b[A\nProcessing:   2%|▏         | 8/352 [00:02<01:55,  2.98it/s]\u001b[A\nProcessing:   3%|▎         | 9/352 [00:03<01:54,  3.00it/s]\u001b[A\nProcessing:   3%|▎         | 10/352 [00:03<02:09,  2.65it/s]\u001b[A\nProcessing:   3%|▎         | 11/352 [00:03<01:56,  2.94it/s]\u001b[A\nProcessing:   3%|▎         | 12/352 [00:04<01:58,  2.86it/s]\u001b[A\nProcessing:   4%|▎         | 13/352 [00:04<01:52,  3.01it/s]\u001b[A\nProcessing:   4%|▍         | 14/352 [00:04<01:45,  3.22it/s]\u001b[A\nProcessing:   4%|▍         | 15/352 [00:05<01:46,  3.16it/s]\u001b[A\nProcessing:   5%|▍         | 16/352 [00:05<01:38,  3.42it/s]\u001b[A\nProcessing:   5%|▍         | 17/352 [00:05<01:35,  3.52it/s]\u001b[A\nProcessing:   5%|▌         | 18/352 [00:05<01:35,  3.50it/s]\u001b[A\nProcessing:   5%|▌         | 19/352 [00:06<01:48,  3.07it/s]\u001b[A\nProcessing:   6%|▌         | 20/352 [00:06<01:44,  3.19it/s]\u001b[A\nProcessing:   6%|▌         | 21/352 [00:06<01:36,  3.43it/s]\u001b[A\nProcessing:   6%|▋         | 22/352 [00:07<01:35,  3.45it/s]\u001b[A\nProcessing:   7%|▋         | 23/352 [00:07<01:39,  3.30it/s]\u001b[A\nProcessing:   7%|▋         | 24/352 [00:07<01:37,  3.36it/s]\u001b[A\nProcessing:   7%|▋         | 25/352 [00:08<01:46,  3.08it/s]\u001b[A\nProcessing:   7%|▋         | 26/352 [00:08<01:51,  2.93it/s]\u001b[A\nProcessing:   8%|▊         | 27/352 [00:08<01:48,  2.99it/s]\u001b[A\nProcessing:   8%|▊         | 28/352 [00:09<01:52,  2.89it/s]\u001b[A\nProcessing:   8%|▊         | 29/352 [00:09<01:43,  3.12it/s]\u001b[A\nProcessing:   9%|▊         | 30/352 [00:09<01:43,  3.12it/s]\u001b[A\nProcessing:   9%|▉         | 31/352 [00:10<01:48,  2.95it/s]\u001b[A\nProcessing:   9%|▉         | 32/352 [00:10<01:51,  2.86it/s]\u001b[A\nProcessing:   9%|▉         | 33/352 [00:10<01:43,  3.08it/s]\u001b[A\nProcessing:  10%|▉         | 34/352 [00:11<01:40,  3.17it/s]\u001b[A\nProcessing:  10%|▉         | 35/352 [00:11<01:53,  2.80it/s]\u001b[A\nProcessing:  10%|█         | 36/352 [00:11<01:52,  2.81it/s]\u001b[A\nProcessing:  11%|█         | 37/352 [00:12<01:50,  2.84it/s]\u001b[A\nProcessing:  11%|█         | 38/352 [00:12<01:45,  2.97it/s]\u001b[A\nProcessing:  11%|█         | 39/352 [00:12<01:53,  2.75it/s]\u001b[A\nProcessing:  11%|█▏        | 40/352 [00:13<01:51,  2.80it/s]\u001b[A\nProcessing:  12%|█▏        | 41/352 [00:13<01:59,  2.60it/s]\u001b[A\nProcessing:  12%|█▏        | 42/352 [00:13<01:44,  2.95it/s]\u001b[A\nProcessing:  12%|█▏        | 43/352 [00:14<01:46,  2.91it/s]\u001b[A\nProcessing:  12%|█▎        | 44/352 [00:14<01:41,  3.05it/s]\u001b[A\nProcessing:  13%|█▎        | 45/352 [00:15<02:14,  2.29it/s]\u001b[A\nProcessing:  13%|█▎        | 46/352 [00:15<02:06,  2.43it/s]\u001b[A\nProcessing:  13%|█▎        | 47/352 [00:16<02:02,  2.48it/s]\u001b[A\nProcessing:  14%|█▎        | 48/352 [00:16<02:04,  2.44it/s]\u001b[A\nProcessing:  14%|█▍        | 49/352 [00:16<02:13,  2.28it/s]\u001b[A\nProcessing:  14%|█▍        | 50/352 [00:17<01:52,  2.69it/s]\u001b[A\nProcessing:  14%|█▍        | 51/352 [00:17<01:48,  2.78it/s]\u001b[A\nProcessing:  15%|█▍        | 52/352 [00:18<02:00,  2.50it/s]\u001b[A\nProcessing:  15%|█▌        | 53/352 [00:18<02:01,  2.46it/s]\u001b[A\nProcessing:  15%|█▌        | 54/352 [00:18<02:06,  2.36it/s]\u001b[A\nProcessing:  16%|█▌        | 55/352 [00:19<01:54,  2.59it/s]\u001b[A\nProcessing:  16%|█▌        | 56/352 [00:19<02:05,  2.37it/s]\u001b[A\nProcessing:  16%|█▌        | 57/352 [00:20<01:54,  2.57it/s]\u001b[A\nProcessing:  16%|█▋        | 58/352 [00:20<01:47,  2.73it/s]\u001b[A\nProcessing:  17%|█▋        | 59/352 [00:20<01:56,  2.51it/s]\u001b[A\nProcessing:  17%|█▋        | 60/352 [00:21<02:01,  2.41it/s]\u001b[A\nProcessing:  17%|█▋        | 61/352 [00:21<01:54,  2.54it/s]\u001b[A\nProcessing:  18%|█▊        | 62/352 [00:21<01:51,  2.60it/s]\u001b[A\nProcessing:  18%|█▊        | 63/352 [00:22<01:43,  2.79it/s]\u001b[A\nProcessing:  18%|█▊        | 64/352 [00:22<01:37,  2.95it/s]\u001b[A\nProcessing:  18%|█▊        | 65/352 [00:22<01:29,  3.22it/s]\u001b[A\nProcessing:  19%|█▉        | 66/352 [00:23<01:30,  3.15it/s]\u001b[A\nProcessing:  19%|█▉        | 67/352 [00:23<01:31,  3.11it/s]\u001b[A\nProcessing:  19%|█▉        | 68/352 [00:23<01:35,  2.98it/s]\u001b[A\nProcessing:  20%|█▉        | 69/352 [00:24<01:34,  3.00it/s]\u001b[A\nProcessing:  20%|█▉        | 70/352 [00:24<01:38,  2.87it/s]\u001b[A\nProcessing:  20%|██        | 71/352 [00:25<02:17,  2.04it/s]\u001b[A\nProcessing:  20%|██        | 72/352 [00:25<01:59,  2.34it/s]\u001b[A\nProcessing:  21%|██        | 73/352 [00:25<01:52,  2.48it/s]\u001b[A\nProcessing:  21%|██        | 74/352 [00:26<01:48,  2.57it/s]\u001b[A\nProcessing:  21%|██▏       | 75/352 [00:26<01:38,  2.82it/s]\u001b[A\nProcessing:  22%|██▏       | 76/352 [00:27<02:05,  2.19it/s]\u001b[A\nProcessing:  22%|██▏       | 77/352 [00:27<01:57,  2.35it/s]\u001b[A\nProcessing:  22%|██▏       | 78/352 [00:28<01:52,  2.44it/s]\u001b[A\nProcessing:  22%|██▏       | 79/352 [00:28<01:37,  2.80it/s]\u001b[A\nProcessing:  23%|██▎       | 80/352 [00:28<01:27,  3.10it/s]\u001b[A\nProcessing:  23%|██▎       | 81/352 [00:28<01:33,  2.89it/s]\u001b[A\nProcessing:  23%|██▎       | 82/352 [00:29<01:37,  2.77it/s]\u001b[A\nProcessing:  24%|██▎       | 83/352 [00:29<01:31,  2.95it/s]\u001b[A\nProcessing:  24%|██▍       | 84/352 [00:29<01:29,  2.99it/s]\u001b[A\nProcessing:  24%|██▍       | 85/352 [00:30<01:17,  3.45it/s]\u001b[A\nProcessing:  24%|██▍       | 86/352 [00:30<01:17,  3.41it/s]\u001b[A\nProcessing:  25%|██▍       | 87/352 [00:30<01:13,  3.59it/s]\u001b[A\nProcessing:  25%|██▌       | 88/352 [00:31<01:19,  3.32it/s]\u001b[A\nProcessing:  25%|██▌       | 89/352 [00:31<01:19,  3.32it/s]\u001b[A\nProcessing:  26%|██▌       | 90/352 [00:31<01:28,  2.95it/s]\u001b[A\nProcessing:  26%|██▌       | 91/352 [00:32<01:31,  2.85it/s]\u001b[A\nProcessing:  26%|██▌       | 92/352 [00:32<01:26,  3.01it/s]\u001b[A\nProcessing:  26%|██▋       | 93/352 [00:32<01:24,  3.08it/s]\u001b[A\nProcessing:  27%|██▋       | 94/352 [00:33<01:26,  2.98it/s]\u001b[A\nProcessing:  27%|██▋       | 95/352 [00:33<01:53,  2.26it/s]\u001b[A\nProcessing:  27%|██▋       | 96/352 [00:34<01:57,  2.17it/s]\u001b[A\nProcessing:  28%|██▊       | 97/352 [00:34<01:50,  2.30it/s]\u001b[A\nProcessing:  28%|██▊       | 98/352 [00:35<01:56,  2.19it/s]\u001b[A\nProcessing:  28%|██▊       | 99/352 [00:35<01:39,  2.53it/s]\u001b[A\nProcessing:  28%|██▊       | 100/352 [00:35<01:26,  2.90it/s]\u001b[A\nProcessing:  29%|██▊       | 101/352 [00:35<01:23,  3.00it/s]\u001b[A\nProcessing:  29%|██▉       | 102/352 [00:36<01:29,  2.80it/s]\u001b[A\nProcessing:  29%|██▉       | 103/352 [00:36<01:36,  2.57it/s]\u001b[A\nProcessing:  30%|██▉       | 104/352 [00:37<01:37,  2.55it/s]\u001b[A\nProcessing:  30%|██▉       | 105/352 [00:37<01:42,  2.41it/s]\u001b[A\nProcessing:  30%|███       | 106/352 [00:38<01:39,  2.47it/s]\u001b[A\nProcessing:  30%|███       | 107/352 [00:38<01:31,  2.67it/s]\u001b[A\nProcessing:  31%|███       | 108/352 [00:38<01:36,  2.53it/s]\u001b[A\nProcessing:  31%|███       | 109/352 [00:39<01:29,  2.71it/s]\u001b[A\nProcessing:  31%|███▏      | 110/352 [00:39<01:21,  2.96it/s]\u001b[A\nProcessing:  32%|███▏      | 111/352 [00:39<01:24,  2.86it/s]\u001b[A\nProcessing:  32%|███▏      | 112/352 [00:40<01:20,  2.98it/s]\u001b[A\nProcessing:  32%|███▏      | 113/352 [00:40<01:19,  3.00it/s]\u001b[A\nProcessing:  32%|███▏      | 114/352 [00:40<01:23,  2.84it/s]\u001b[A\nProcessing:  33%|███▎      | 115/352 [00:41<01:32,  2.56it/s]\u001b[A\nProcessing:  33%|███▎      | 116/352 [00:41<01:35,  2.46it/s]\u001b[A\nProcessing:  33%|███▎      | 117/352 [00:42<01:31,  2.58it/s]\u001b[A\nProcessing:  34%|███▎      | 118/352 [00:42<01:46,  2.20it/s]\u001b[A\nProcessing:  34%|███▍      | 119/352 [00:43<01:44,  2.22it/s]\u001b[A\nProcessing:  34%|███▍      | 120/352 [00:43<01:35,  2.42it/s]\u001b[A\nProcessing:  34%|███▍      | 121/352 [00:43<01:34,  2.46it/s]\u001b[A\nProcessing:  35%|███▍      | 122/352 [00:44<01:44,  2.20it/s]\u001b[A\nProcessing:  35%|███▍      | 123/352 [00:44<01:27,  2.61it/s]\u001b[A\nProcessing:  35%|███▌      | 124/352 [00:45<01:31,  2.49it/s]\u001b[A\nProcessing:  36%|███▌      | 125/352 [00:45<01:31,  2.49it/s]\u001b[A\nProcessing:  36%|███▌      | 126/352 [00:45<01:28,  2.56it/s]\u001b[A\nProcessing:  36%|███▌      | 127/352 [00:46<01:31,  2.45it/s]\u001b[A\nProcessing:  36%|███▋      | 128/352 [00:46<01:29,  2.51it/s]\u001b[A\nProcessing:  37%|███▋      | 129/352 [00:46<01:16,  2.91it/s]\u001b[A\nProcessing:  37%|███▋      | 130/352 [00:47<01:26,  2.57it/s]\u001b[A\nProcessing:  37%|███▋      | 131/352 [00:47<01:34,  2.34it/s]\u001b[A\nProcessing:  38%|███▊      | 132/352 [00:48<01:27,  2.53it/s]\u001b[A\nProcessing:  38%|███▊      | 133/352 [00:48<01:25,  2.55it/s]\u001b[A\nProcessing:  38%|███▊      | 134/352 [00:49<01:33,  2.34it/s]\u001b[A\nProcessing:  38%|███▊      | 135/352 [00:49<01:29,  2.43it/s]\u001b[A\nProcessing:  39%|███▊      | 136/352 [00:49<01:32,  2.33it/s]\u001b[A\nProcessing:  39%|███▉      | 137/352 [00:50<01:33,  2.31it/s]\u001b[A\nProcessing:  39%|███▉      | 138/352 [00:50<01:34,  2.25it/s]\u001b[A\nProcessing:  39%|███▉      | 139/352 [00:51<01:19,  2.69it/s]\u001b[A\nProcessing:  40%|███▉      | 140/352 [00:51<01:10,  3.01it/s]\u001b[A\nProcessing:  40%|████      | 141/352 [00:51<01:10,  2.98it/s]\u001b[A\nProcessing:  40%|████      | 142/352 [00:51<01:05,  3.21it/s]\u001b[A\nProcessing:  41%|████      | 143/352 [00:52<01:12,  2.87it/s]\u001b[A\nProcessing:  41%|████      | 144/352 [00:52<01:06,  3.12it/s]\u001b[A\nProcessing:  41%|████      | 145/352 [00:52<01:05,  3.15it/s]\u001b[A\nProcessing:  41%|████▏     | 146/352 [00:53<01:12,  2.84it/s]\u001b[A\nProcessing:  42%|████▏     | 147/352 [00:53<01:12,  2.82it/s]\u001b[A\nProcessing:  42%|████▏     | 148/352 [00:54<01:18,  2.59it/s]\u001b[A\nProcessing:  42%|████▏     | 149/352 [00:54<01:15,  2.68it/s]\u001b[A\nProcessing:  43%|████▎     | 150/352 [00:54<01:03,  3.19it/s]\u001b[A\nProcessing:  43%|████▎     | 151/352 [00:54<01:04,  3.14it/s]\u001b[A\nProcessing:  43%|████▎     | 152/352 [00:55<01:14,  2.70it/s]\u001b[A\nProcessing:  43%|████▎     | 153/352 [00:55<01:01,  3.22it/s]\u001b[A\nProcessing:  44%|████▍     | 154/352 [00:56<01:09,  2.86it/s]\u001b[A\nProcessing:  44%|████▍     | 155/352 [00:56<01:25,  2.30it/s]\u001b[A\nProcessing:  44%|████▍     | 156/352 [00:57<01:19,  2.46it/s]\u001b[A\nProcessing:  45%|████▍     | 157/352 [00:57<01:26,  2.27it/s]\u001b[A\nProcessing:  45%|████▍     | 158/352 [00:57<01:22,  2.36it/s]\u001b[A\nProcessing:  45%|████▌     | 159/352 [00:58<01:18,  2.47it/s]\u001b[A\nProcessing:  45%|████▌     | 160/352 [00:58<01:14,  2.57it/s]\u001b[A\nProcessing:  46%|████▌     | 161/352 [00:59<01:17,  2.48it/s]\u001b[A\nProcessing:  46%|████▌     | 162/352 [00:59<01:17,  2.46it/s]\u001b[A\nProcessing:  46%|████▋     | 163/352 [00:59<01:17,  2.45it/s]\u001b[A\nProcessing:  47%|████▋     | 164/352 [01:00<01:12,  2.59it/s]\u001b[A\nProcessing:  47%|████▋     | 165/352 [01:00<01:07,  2.75it/s]\u001b[A\nProcessing:  47%|████▋     | 166/352 [01:01<01:12,  2.56it/s]\u001b[A\nProcessing:  47%|████▋     | 167/352 [01:01<01:14,  2.47it/s]\u001b[A\nProcessing:  48%|████▊     | 168/352 [01:01<01:18,  2.35it/s]\u001b[A\nProcessing:  48%|████▊     | 169/352 [01:02<01:13,  2.50it/s]\u001b[A\nProcessing:  48%|████▊     | 170/352 [01:02<01:27,  2.09it/s]\u001b[A\nProcessing:  49%|████▊     | 171/352 [01:03<01:17,  2.34it/s]\u001b[A\nProcessing:  49%|████▉     | 172/352 [01:03<01:22,  2.19it/s]\u001b[A\nProcessing:  49%|████▉     | 173/352 [01:04<01:13,  2.43it/s]\u001b[A\nProcessing:  49%|████▉     | 174/352 [01:04<01:10,  2.54it/s]\u001b[A\nProcessing:  50%|████▉     | 175/352 [01:04<01:07,  2.60it/s]\u001b[A\nProcessing:  50%|█████     | 176/352 [01:05<00:58,  3.03it/s]\u001b[A\nProcessing:  50%|█████     | 177/352 [01:05<00:59,  2.93it/s]\u001b[A\nProcessing:  51%|█████     | 178/352 [01:05<01:07,  2.57it/s]\u001b[A\nProcessing:  51%|█████     | 179/352 [01:06<01:01,  2.82it/s]\u001b[A\nProcessing:  51%|█████     | 180/352 [01:06<00:57,  2.99it/s]\u001b[A\nProcessing:  51%|█████▏    | 181/352 [01:06<00:57,  3.00it/s]\u001b[A\nProcessing:  52%|█████▏    | 182/352 [01:07<00:54,  3.11it/s]\u001b[A\nProcessing:  52%|█████▏    | 183/352 [01:07<00:49,  3.42it/s]\u001b[A\nProcessing:  52%|█████▏    | 184/352 [01:07<00:51,  3.26it/s]\u001b[A\nProcessing:  53%|█████▎    | 185/352 [01:07<00:53,  3.11it/s]\u001b[A\nProcessing:  53%|█████▎    | 186/352 [01:08<00:53,  3.12it/s]\u001b[A\nProcessing:  53%|█████▎    | 187/352 [01:08<00:58,  2.84it/s]\u001b[A\nProcessing:  53%|█████▎    | 188/352 [01:09<01:09,  2.36it/s]\u001b[A\nProcessing:  54%|█████▎    | 189/352 [01:09<01:02,  2.61it/s]\u001b[A\nProcessing:  54%|█████▍    | 190/352 [01:10<01:13,  2.21it/s]\u001b[A\nProcessing:  54%|█████▍    | 191/352 [01:10<01:05,  2.45it/s]\u001b[A\nProcessing:  55%|█████▍    | 192/352 [01:10<01:03,  2.54it/s]\u001b[A\nProcessing:  55%|█████▍    | 193/352 [01:11<01:02,  2.55it/s]\u001b[A\nProcessing:  55%|█████▌    | 194/352 [01:11<01:13,  2.15it/s]\u001b[A\nProcessing:  55%|█████▌    | 195/352 [01:12<01:06,  2.35it/s]\u001b[A\nProcessing:  56%|█████▌    | 196/352 [01:12<01:03,  2.47it/s]\u001b[A\nProcessing:  56%|█████▌    | 197/352 [01:12<01:01,  2.53it/s]\u001b[A\nProcessing:  56%|█████▋    | 198/352 [01:13<00:51,  3.01it/s]\u001b[A\nProcessing:  57%|█████▋    | 199/352 [01:13<00:48,  3.17it/s]\u001b[A\nProcessing:  57%|█████▋    | 200/352 [01:13<00:48,  3.10it/s]\u001b[A\nProcessing:  57%|█████▋    | 201/352 [01:14<00:50,  3.00it/s]\u001b[A\nProcessing:  57%|█████▋    | 202/352 [01:14<00:53,  2.82it/s]\u001b[A\nProcessing:  58%|█████▊    | 203/352 [01:14<00:48,  3.04it/s]\u001b[A\nProcessing:  58%|█████▊    | 204/352 [01:15<00:46,  3.16it/s]\u001b[A\nProcessing:  58%|█████▊    | 205/352 [01:15<00:54,  2.69it/s]\u001b[A\nProcessing:  59%|█████▊    | 206/352 [01:15<00:46,  3.12it/s]\u001b[A\nProcessing:  59%|█████▉    | 207/352 [01:16<00:46,  3.11it/s]\u001b[A\nProcessing:  59%|█████▉    | 208/352 [01:16<00:47,  3.06it/s]\u001b[A\nProcessing:  59%|█████▉    | 209/352 [01:16<00:52,  2.71it/s]\u001b[A\nProcessing:  60%|█████▉    | 210/352 [01:17<00:48,  2.90it/s]\u001b[A\nProcessing:  60%|█████▉    | 211/352 [01:17<00:46,  3.01it/s]\u001b[A\nProcessing:  60%|██████    | 212/352 [01:17<00:50,  2.78it/s]\u001b[A\nProcessing:  61%|██████    | 213/352 [01:18<00:48,  2.84it/s]\u001b[A\nProcessing:  61%|██████    | 214/352 [01:18<01:02,  2.22it/s]\u001b[A\nProcessing:  61%|██████    | 215/352 [01:19<00:57,  2.38it/s]\u001b[A\nProcessing:  61%|██████▏   | 216/352 [01:19<00:50,  2.68it/s]\u001b[A\nProcessing:  62%|██████▏   | 217/352 [01:19<00:46,  2.91it/s]\u001b[A\nProcessing:  62%|██████▏   | 218/352 [01:20<00:47,  2.83it/s]\u001b[A\nProcessing:  62%|██████▏   | 219/352 [01:20<00:44,  3.00it/s]\u001b[A\nProcessing:  62%|██████▎   | 220/352 [01:20<00:45,  2.89it/s]\u001b[A\nProcessing:  63%|██████▎   | 221/352 [01:21<00:44,  2.97it/s]\u001b[A\nProcessing:  63%|██████▎   | 222/352 [01:21<00:48,  2.65it/s]\u001b[A\nProcessing:  63%|██████▎   | 223/352 [01:21<00:45,  2.85it/s]\u001b[A\nProcessing:  64%|██████▎   | 224/352 [01:22<00:45,  2.82it/s]\u001b[A\nProcessing:  64%|██████▍   | 225/352 [01:22<00:42,  2.99it/s]\u001b[A\nProcessing:  64%|██████▍   | 226/352 [01:22<00:41,  3.07it/s]\u001b[A\nProcessing:  64%|██████▍   | 227/352 [01:23<00:41,  2.99it/s]\u001b[A\nProcessing:  65%|██████▍   | 228/352 [01:23<00:40,  3.03it/s]\u001b[A\nProcessing:  65%|██████▌   | 229/352 [01:23<00:42,  2.87it/s]\u001b[A\nProcessing:  65%|██████▌   | 230/352 [01:24<00:45,  2.70it/s]\u001b[A\nProcessing:  66%|██████▌   | 231/352 [01:24<00:45,  2.67it/s]\u001b[A\nProcessing:  66%|██████▌   | 232/352 [01:25<00:42,  2.80it/s]\u001b[A\nProcessing:  66%|██████▌   | 233/352 [01:25<00:45,  2.64it/s]\u001b[A\nProcessing:  66%|██████▋   | 234/352 [01:25<00:41,  2.82it/s]\u001b[A\nProcessing:  67%|██████▋   | 235/352 [01:26<00:39,  2.97it/s]\u001b[A\nProcessing:  67%|██████▋   | 236/352 [01:26<00:39,  2.91it/s]\u001b[A\nProcessing:  67%|██████▋   | 237/352 [01:26<00:35,  3.21it/s]\u001b[A\nProcessing:  68%|██████▊   | 238/352 [01:26<00:34,  3.31it/s]\u001b[A\nProcessing:  68%|██████▊   | 239/352 [01:27<00:42,  2.63it/s]\u001b[A\nProcessing:  68%|██████▊   | 240/352 [01:27<00:38,  2.88it/s]\u001b[A\nProcessing:  68%|██████▊   | 241/352 [01:28<00:42,  2.59it/s]\u001b[A\nProcessing:  69%|██████▉   | 242/352 [01:28<00:48,  2.26it/s]\u001b[A\nProcessing:  69%|██████▉   | 243/352 [01:29<00:45,  2.38it/s]\u001b[A\nProcessing:  69%|██████▉   | 244/352 [01:29<00:39,  2.75it/s]\u001b[A\nProcessing:  70%|██████▉   | 245/352 [01:29<00:39,  2.68it/s]\u001b[A\nProcessing:  70%|██████▉   | 246/352 [01:30<00:33,  3.16it/s]\u001b[A\nProcessing:  70%|███████   | 247/352 [01:30<00:39,  2.66it/s]\u001b[A\nProcessing:  70%|███████   | 248/352 [01:30<00:35,  2.91it/s]\u001b[A\nProcessing:  71%|███████   | 249/352 [01:31<00:36,  2.79it/s]\u001b[A\nProcessing:  71%|███████   | 250/352 [01:31<00:36,  2.77it/s]\u001b[A\nProcessing:  71%|███████▏  | 251/352 [01:32<00:39,  2.58it/s]\u001b[A\nProcessing:  72%|███████▏  | 252/352 [01:32<00:38,  2.62it/s]\u001b[A\nProcessing:  72%|███████▏  | 253/352 [01:32<00:34,  2.85it/s]\u001b[A\nProcessing:  72%|███████▏  | 254/352 [01:33<00:37,  2.61it/s]\u001b[A\nProcessing:  72%|███████▏  | 255/352 [01:33<00:34,  2.83it/s]\u001b[A\nProcessing:  73%|███████▎  | 256/352 [01:33<00:37,  2.58it/s]\u001b[A\nProcessing:  73%|███████▎  | 257/352 [01:34<00:34,  2.76it/s]\u001b[A\nProcessing:  73%|███████▎  | 258/352 [01:34<00:30,  3.12it/s]\u001b[A\nProcessing:  74%|███████▎  | 259/352 [01:34<00:28,  3.27it/s]\u001b[A\nProcessing:  74%|███████▍  | 260/352 [01:35<00:29,  3.12it/s]\u001b[A\nProcessing:  74%|███████▍  | 261/352 [01:35<00:29,  3.05it/s]\u001b[A\nProcessing:  74%|███████▍  | 262/352 [01:35<00:32,  2.80it/s]\u001b[A\nProcessing:  75%|███████▍  | 263/352 [01:36<00:32,  2.71it/s]\u001b[A\nProcessing:  75%|███████▌  | 264/352 [01:36<00:34,  2.52it/s]\u001b[A\nProcessing:  75%|███████▌  | 265/352 [01:37<00:33,  2.56it/s]\u001b[A\nProcessing:  76%|███████▌  | 266/352 [01:37<00:35,  2.45it/s]\u001b[A\nProcessing:  76%|███████▌  | 267/352 [01:37<00:33,  2.50it/s]\u001b[A\nProcessing:  76%|███████▌  | 268/352 [01:38<00:31,  2.67it/s]\u001b[A\nProcessing:  76%|███████▋  | 269/352 [01:38<00:30,  2.70it/s]\u001b[A\nProcessing:  77%|███████▋  | 270/352 [01:39<00:32,  2.52it/s]\u001b[A\nProcessing:  77%|███████▋  | 271/352 [01:39<00:28,  2.85it/s]\u001b[A\nProcessing:  77%|███████▋  | 272/352 [01:39<00:32,  2.44it/s]\u001b[A\nProcessing:  78%|███████▊  | 273/352 [01:40<00:30,  2.62it/s]\u001b[A\nProcessing:  78%|███████▊  | 274/352 [01:40<00:24,  3.13it/s]\u001b[A\nProcessing:  78%|███████▊  | 275/352 [01:40<00:27,  2.77it/s]\u001b[A\nProcessing:  78%|███████▊  | 276/352 [01:41<00:29,  2.62it/s]\u001b[A\nProcessing:  79%|███████▊  | 277/352 [01:41<00:34,  2.17it/s]\u001b[A\nProcessing:  79%|███████▉  | 278/352 [01:42<00:31,  2.38it/s]\u001b[A\nProcessing:  79%|███████▉  | 279/352 [01:42<00:28,  2.57it/s]\u001b[A\nProcessing:  80%|███████▉  | 280/352 [01:43<00:30,  2.35it/s]\u001b[A\nProcessing:  80%|███████▉  | 281/352 [01:43<00:27,  2.60it/s]\u001b[A\nProcessing:  80%|████████  | 282/352 [01:43<00:25,  2.70it/s]\u001b[A\nProcessing:  80%|████████  | 283/352 [01:44<00:33,  2.09it/s]\u001b[A\nProcessing:  81%|████████  | 284/352 [01:44<00:30,  2.26it/s]\u001b[A\nProcessing:  81%|████████  | 285/352 [01:44<00:24,  2.74it/s]\u001b[A\nProcessing:  81%|████████▏ | 286/352 [01:45<00:23,  2.80it/s]\u001b[A\nProcessing:  82%|████████▏ | 287/352 [01:45<00:22,  2.94it/s]\u001b[A\nProcessing:  82%|████████▏ | 288/352 [01:45<00:22,  2.89it/s]\u001b[A\nProcessing:  82%|████████▏ | 289/352 [01:46<00:22,  2.76it/s]\u001b[A\nProcessing:  82%|████████▏ | 290/352 [01:46<00:21,  2.82it/s]\u001b[A\nProcessing:  83%|████████▎ | 291/352 [01:46<00:21,  2.84it/s]\u001b[A\nProcessing:  83%|████████▎ | 292/352 [01:47<00:24,  2.42it/s]\u001b[A\nProcessing:  83%|████████▎ | 293/352 [01:48<00:25,  2.34it/s]\u001b[A\nProcessing:  84%|████████▎ | 294/352 [01:48<00:22,  2.61it/s]\u001b[A\nProcessing:  84%|████████▍ | 295/352 [01:48<00:21,  2.66it/s]\u001b[A\nProcessing:  84%|████████▍ | 296/352 [01:48<00:19,  2.93it/s]\u001b[A\nProcessing:  84%|████████▍ | 297/352 [01:49<00:17,  3.22it/s]\u001b[A\nProcessing:  85%|████████▍ | 298/352 [01:49<00:17,  3.10it/s]\u001b[A\nProcessing:  85%|████████▍ | 299/352 [01:49<00:17,  3.09it/s]\u001b[A\nProcessing:  85%|████████▌ | 300/352 [01:50<00:17,  2.90it/s]\u001b[A\nProcessing:  86%|████████▌ | 301/352 [01:50<00:18,  2.69it/s]\u001b[A\nProcessing:  86%|████████▌ | 302/352 [01:51<00:19,  2.62it/s]\u001b[A\nProcessing:  86%|████████▌ | 303/352 [01:51<00:18,  2.70it/s]\u001b[A\nProcessing:  86%|████████▋ | 304/352 [01:51<00:15,  3.02it/s]\u001b[A\nProcessing:  87%|████████▋ | 305/352 [01:52<00:17,  2.64it/s]\u001b[A\nProcessing:  87%|████████▋ | 306/352 [01:52<00:17,  2.70it/s]\u001b[A\nProcessing:  87%|████████▋ | 307/352 [01:52<00:16,  2.69it/s]\u001b[A\nProcessing:  88%|████████▊ | 308/352 [01:53<00:15,  2.79it/s]\u001b[A\nProcessing:  88%|████████▊ | 309/352 [01:53<00:14,  2.88it/s]\u001b[A\nProcessing:  88%|████████▊ | 310/352 [01:53<00:14,  2.91it/s]\u001b[A\nProcessing:  88%|████████▊ | 311/352 [01:54<00:14,  2.87it/s]\u001b[A\nProcessing:  89%|████████▊ | 312/352 [01:54<00:15,  2.53it/s]\u001b[A\nProcessing:  89%|████████▉ | 313/352 [01:55<00:15,  2.60it/s]\u001b[A\nProcessing:  89%|████████▉ | 314/352 [01:55<00:12,  2.96it/s]\u001b[A\nProcessing:  89%|████████▉ | 315/352 [01:55<00:12,  2.96it/s]\u001b[A\nProcessing:  90%|████████▉ | 316/352 [01:55<00:11,  3.10it/s]\u001b[A\nProcessing:  90%|█████████ | 317/352 [01:56<00:11,  3.17it/s]\u001b[A\nProcessing:  90%|█████████ | 318/352 [01:56<00:11,  2.96it/s]\u001b[A\nProcessing:  91%|█████████ | 319/352 [01:56<00:09,  3.32it/s]\u001b[A\nProcessing:  91%|█████████ | 320/352 [01:57<00:10,  3.00it/s]\u001b[A\nProcessing:  91%|█████████ | 321/352 [01:57<00:09,  3.27it/s]\u001b[A\nProcessing:  91%|█████████▏| 322/352 [01:57<00:10,  2.73it/s]\u001b[A\nProcessing:  92%|█████████▏| 323/352 [01:58<00:12,  2.33it/s]\u001b[A\nProcessing:  92%|█████████▏| 324/352 [01:58<00:11,  2.38it/s]\u001b[A\nProcessing:  92%|█████████▏| 325/352 [01:59<00:09,  2.89it/s]\u001b[A\nProcessing:  93%|█████████▎| 326/352 [01:59<00:08,  2.93it/s]\u001b[A\nProcessing:  93%|█████████▎| 327/352 [01:59<00:08,  3.10it/s]\u001b[A\nProcessing:  93%|█████████▎| 328/352 [02:00<00:08,  2.81it/s]\u001b[A\nProcessing:  93%|█████████▎| 329/352 [02:00<00:07,  2.89it/s]\u001b[A\nProcessing:  94%|█████████▍| 330/352 [02:00<00:07,  3.12it/s]\u001b[A\nProcessing:  94%|█████████▍| 331/352 [02:01<00:06,  3.05it/s]\u001b[A\nProcessing:  94%|█████████▍| 332/352 [02:01<00:07,  2.84it/s]\u001b[A\nProcessing:  95%|█████████▍| 333/352 [02:01<00:07,  2.66it/s]\u001b[A\nProcessing:  95%|█████████▍| 334/352 [02:02<00:06,  2.75it/s]\u001b[A\nProcessing:  95%|█████████▌| 335/352 [02:02<00:05,  2.98it/s]\u001b[A\nProcessing:  95%|█████████▌| 336/352 [02:03<00:06,  2.39it/s]\u001b[A\nProcessing:  96%|█████████▌| 337/352 [02:03<00:06,  2.43it/s]\u001b[A\nProcessing:  96%|█████████▌| 338/352 [02:03<00:05,  2.36it/s]\u001b[A\nProcessing:  96%|█████████▋| 339/352 [02:04<00:05,  2.37it/s]\u001b[A\nProcessing:  97%|█████████▋| 340/352 [02:04<00:04,  2.73it/s]\u001b[A\nProcessing:  97%|█████████▋| 341/352 [02:05<00:04,  2.44it/s]\u001b[A\nProcessing:  97%|█████████▋| 342/352 [02:05<00:04,  2.27it/s]\u001b[A\nProcessing:  97%|█████████▋| 343/352 [02:06<00:03,  2.36it/s]\u001b[A\nProcessing:  98%|█████████▊| 344/352 [02:06<00:03,  2.40it/s]\u001b[A\nProcessing:  98%|█████████▊| 345/352 [02:06<00:02,  2.41it/s]\u001b[A\nProcessing:  98%|█████████▊| 346/352 [02:07<00:02,  2.48it/s]\u001b[A\nProcessing:  99%|█████████▊| 347/352 [02:07<00:01,  2.79it/s]\u001b[A\nProcessing:  99%|█████████▉| 348/352 [02:07<00:01,  2.75it/s]\u001b[A\nProcessing:  99%|█████████▉| 349/352 [02:08<00:01,  2.94it/s]\u001b[A\nProcessing:  99%|█████████▉| 350/352 [02:08<00:00,  3.21it/s]\u001b[A\nProcessing: 100%|█████████▉| 351/352 [02:08<00:00,  3.23it/s]\u001b[A\nProcessing: 100%|██████████| 352/352 [02:09<00:00,  2.65it/s]\u001b[A\n                                                             \u001b[A","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"predictions_1 = pd.DataFrame({0:pids, 1:source, 2:target, 3:pred})\npredictions_1\n# print(pred)\npredictions = pd.DataFrame({0:target, 1:pred})\npredictions","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:18:21.044543Z","iopub.execute_input":"2024-09-29T13:18:21.044949Z","iopub.status.idle":"2024-09-29T13:18:21.065687Z","shell.execute_reply.started":"2024-09-29T13:18:21.044910Z","shell.execute_reply":"2024-09-29T13:18:21.064792Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                                                     0  \\\n0    the author hates the design of this convention...   \n1             the author hates working late from home.   \n2    your anxiety is not cured when someone says \"d...   \n3    the author is pissed to watch a full train lea...   \n4    the author doesn't find such notifications fro...   \n..                                                 ...   \n347          it isn't a cool week if it's 100 degrees.   \n348  she's exactly like her dad, both are making si...   \n349  the author is disappointed with this eclipse s...   \n350            <user> app radar isn't right on target.   \n351  the author doesn't like to kick off her start ...   \n\n                                                     1  \n0     the author is pissed at <user> for having a g...  \n1      the author hates having to work late from home.  \n2     the author is pissed at <user> for not fixing...  \n3     the author is pissed at <user> for having to ...  \n4     the author is pissed at <user> for not gettin...  \n..                                                 ...  \n347    it's very annoying when you're being sarcastic.  \n348                   the author had fun with his mom.  \n349               this eclipse isn't even a good idea.  \n350            the author's disappointed with the app.  \n351   the author doesn't want to take a good way to...  \n\n[352 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the author hates the design of this convention...</td>\n      <td>the author is pissed at &lt;user&gt; for having a g...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the author hates working late from home.</td>\n      <td>the author hates having to work late from home.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>your anxiety is not cured when someone says \"d...</td>\n      <td>the author is pissed at &lt;user&gt; for not fixing...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the author is pissed to watch a full train lea...</td>\n      <td>the author is pissed at &lt;user&gt; for having to ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the author doesn't find such notifications fro...</td>\n      <td>the author is pissed at &lt;user&gt; for not gettin...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>347</th>\n      <td>it isn't a cool week if it's 100 degrees.</td>\n      <td>it's very annoying when you're being sarcastic.</td>\n    </tr>\n    <tr>\n      <th>348</th>\n      <td>she's exactly like her dad, both are making si...</td>\n      <td>the author had fun with his mom.</td>\n    </tr>\n    <tr>\n      <th>349</th>\n      <td>the author is disappointed with this eclipse s...</td>\n      <td>this eclipse isn't even a good idea.</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>&lt;user&gt; app radar isn't right on target.</td>\n      <td>the author's disappointed with the app.</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>the author doesn't like to kick off her start ...</td>\n      <td>the author doesn't want to take a good way to...</td>\n    </tr>\n  </tbody>\n</table>\n<p>352 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"path_to_predictions = 'final_outputs'\npredictions_1.to_csv(path_to_predictions, sep='\\t', index=False, header=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:18:34.600003Z","iopub.execute_input":"2024-09-29T13:18:34.600418Z","iopub.status.idle":"2024-09-29T13:18:34.611079Z","shell.execute_reply.started":"2024-09-29T13:18:34.600379Z","shell.execute_reply":"2024-09-29T13:18:34.610236Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# !pip install rouge-score\n# !pip install bert-score\n!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:20:30.495032Z","iopub.execute_input":"2024-09-29T13:20:30.495981Z","iopub.status.idle":"2024-09-29T13:20:42.410629Z","shell.execute_reply.started":"2024-09-29T13:20:30.495940Z","shell.execute_reply":"2024-09-29T13:20:42.409448Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.44.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\nRequirement already satisfied: huggingface-hub>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.25.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.19.3->sentence-transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom rouge_score import rouge_scorer\nimport pandas as pd\nfrom bert_score import score\nimport torch\nfrom sentence_transformers import SentenceTransformer\nfrom scipy import spatial\n\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:21:04.008634Z","iopub.execute_input":"2024-09-29T13:21:04.009331Z","iopub.status.idle":"2024-09-29T13:21:05.807824Z","shell.execute_reply.started":"2024-09-29T13:21:04.009290Z","shell.execute_reply":"2024-09-29T13:21:05.806910Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:21:11.301427Z","iopub.execute_input":"2024-09-29T13:21:11.302410Z","iopub.status.idle":"2024-09-29T13:21:11.306690Z","shell.execute_reply.started":"2024-09-29T13:21:11.302368Z","shell.execute_reply":"2024-09-29T13:21:11.305786Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"sentence_transformer_model = SentenceTransformer('bert-base-nli-mean-tokens')\nsentence_transformer_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:21:13.617735Z","iopub.execute_input":"2024-09-29T13:21:13.618537Z","iopub.status.idle":"2024-09-29T13:21:22.012030Z","shell.execute_reply.started":"2024-09-29T13:21:13.618497Z","shell.execute_reply":"2024-09-29T13:21:22.011093Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73a564617594059a893981447a036b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7fc4b7b07ad42ff848187e441a94095"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.99k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f3bbd39dc9446cebb9cb001a4e8562f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db92dbb6a2b04c28b79a5d75d9120aba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de68e4a4a3bb4d83adcebfb2f27f5880"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"005cb2fc85e843d1b6b366c3f728f5e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f694ccefb10f470faa00169553553acb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afa3ebf4c3994db596b57f89253529e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e219558b61840b796422d9bbd3c180c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2181c7274f44666a6e657d23999bed1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f7828dcc6a641a699d18ba61d9efb06"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3040e24879b24c17a06a93ead7f7ff18"}},"metadata":{}},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"SentenceTransformer(\n  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n)"},"metadata":{}}]},{"cell_type":"code","source":"path_to_preds = \"\"\npredictions = pd.read_csv(path_to_preds, sep=\"\\t\", header=None)\npredictions.columns = ['pid', 'source', 'reference', 'hypothesis']\ny_true = predictions.reference.tolist()\ny_pred = predictions.hypothesis.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T11:49:58.220107Z","iopub.status.idle":"2024-09-29T11:49:58.220478Z","shell.execute_reply.started":"2024-09-29T11:49:58.220299Z","shell.execute_reply":"2024-09-29T11:49:58.220318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ocr_df","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:22:53.022127Z","iopub.execute_input":"2024-09-29T13:22:53.022530Z","iopub.status.idle":"2024-09-29T13:22:53.035980Z","shell.execute_reply.started":"2024-09-29T13:22:53.022492Z","shell.execute_reply":"2024-09-29T13:22:53.035025Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"                                  0  \\\n0                685491413409112065   \n1                700183392969756672   \n2                928753954745475072   \n3                935133439011049473   \n4                933466049697198080   \n..                              ...   \n347  1011850445043480900_1580447253   \n348    636237012294327831_256939246   \n349              899685897251069952   \n350              878368201221914624   \n351              816218446526578688   \n\n                                                     1  \\\n0    'nothing better than # design of convention ce...   \n1    'oh i so love working late from home  # work #...   \n2    'yeaah ! buddy o miracle worker  # infj emoji_...   \n3    'rt <user> : something different ..... a delay...   \n4    'oh really linkedin ? thanks for the super use...   \n..                                                 ...   \n347  âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï...   \n348  She's nothing like her dad... ;) #lovethem #fa...   \n349  'this eclipse is even cooler than i thought it...   \n350  '<user> app radar is definitely right on targe...   \n351  can 't think of a better way to kick off my st...   \n\n                                                     2  \\\n0    the author hates the design of this convention...   \n1             the author hates working late from home.   \n2    your anxiety is not cured when someone says \"d...   \n3    the author is pissed to watch a full train lea...   \n4    the author doesn't find such notifications fro...   \n..                                                 ...   \n347          it isn't a cool week if it's 100 degrees.   \n348  she's exactly like her dad, both are making si...   \n349  the author is disappointed with this eclipse s...   \n350            <user> app radar isn't right on target.   \n351  the author doesn't like to kick off her start ...   \n\n                                                     3  \n0     the author is pissed at <user> for having a g...  \n1      the author hates having to work late from home.  \n2     the author is pissed at <user> for not fixing...  \n3     the author is pissed at <user> for having to ...  \n4     the author is pissed at <user> for not gettin...  \n..                                                 ...  \n347    it's very annoying when you're being sarcastic.  \n348                   the author had fun with his mom.  \n349               this eclipse isn't even a good idea.  \n350            the author's disappointed with the app.  \n351   the author doesn't want to take a good way to...  \n\n[352 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>685491413409112065</td>\n      <td>'nothing better than # design of convention ce...</td>\n      <td>the author hates the design of this convention...</td>\n      <td>the author is pissed at &lt;user&gt; for having a g...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>700183392969756672</td>\n      <td>'oh i so love working late from home  # work #...</td>\n      <td>the author hates working late from home.</td>\n      <td>the author hates having to work late from home.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>928753954745475072</td>\n      <td>'yeaah ! buddy o miracle worker  # infj emoji_...</td>\n      <td>your anxiety is not cured when someone says \"d...</td>\n      <td>the author is pissed at &lt;user&gt; for not fixing...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>935133439011049473</td>\n      <td>'rt &lt;user&gt; : something different ..... a delay...</td>\n      <td>the author is pissed to watch a full train lea...</td>\n      <td>the author is pissed at &lt;user&gt; for having to ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>933466049697198080</td>\n      <td>'oh really linkedin ? thanks for the super use...</td>\n      <td>the author doesn't find such notifications fro...</td>\n      <td>the author is pissed at &lt;user&gt; for not gettin...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>347</th>\n      <td>1011850445043480900_1580447253</td>\n      <td>âï¸âï¸âï¸âï¸âï¸âï¸âï¸âï...</td>\n      <td>it isn't a cool week if it's 100 degrees.</td>\n      <td>it's very annoying when you're being sarcastic.</td>\n    </tr>\n    <tr>\n      <th>348</th>\n      <td>636237012294327831_256939246</td>\n      <td>She's nothing like her dad... ;) #lovethem #fa...</td>\n      <td>she's exactly like her dad, both are making si...</td>\n      <td>the author had fun with his mom.</td>\n    </tr>\n    <tr>\n      <th>349</th>\n      <td>899685897251069952</td>\n      <td>'this eclipse is even cooler than i thought it...</td>\n      <td>the author is disappointed with this eclipse s...</td>\n      <td>this eclipse isn't even a good idea.</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>878368201221914624</td>\n      <td>'&lt;user&gt; app radar is definitely right on targe...</td>\n      <td>&lt;user&gt; app radar isn't right on target.</td>\n      <td>the author's disappointed with the app.</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>816218446526578688</td>\n      <td>can 't think of a better way to kick off my st...</td>\n      <td>the author doesn't like to kick off her start ...</td>\n      <td>the author doesn't want to take a good way to...</td>\n    </tr>\n  </tbody>\n</table>\n<p>352 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:41:10.371550Z","iopub.execute_input":"2024-09-29T13:41:10.371935Z","iopub.status.idle":"2024-09-29T13:41:10.383461Z","shell.execute_reply.started":"2024-09-29T13:41:10.371901Z","shell.execute_reply":"2024-09-29T13:41:10.382542Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"                                                     0  \\\n0    the author hates the design of this convention...   \n1             the author hates working late from home.   \n2    your anxiety is not cured when someone says \"d...   \n3    the author is pissed to watch a full train lea...   \n4    the author doesn't find such notifications fro...   \n..                                                 ...   \n347          it isn't a cool week if it's 100 degrees.   \n348  she's exactly like her dad, both are making si...   \n349  the author is disappointed with this eclipse s...   \n350            <user> app radar isn't right on target.   \n351  the author doesn't like to kick off her start ...   \n\n                                                     1  \n0     the author is pissed at <user> for having a g...  \n1      the author hates having to work late from home.  \n2     the author is pissed at <user> for not fixing...  \n3     the author is pissed at <user> for having to ...  \n4     the author is pissed at <user> for not gettin...  \n..                                                 ...  \n347    it's very annoying when you're being sarcastic.  \n348                   the author had fun with his mom.  \n349               this eclipse isn't even a good idea.  \n350            the author's disappointed with the app.  \n351   the author doesn't want to take a good way to...  \n\n[352 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the author hates the design of this convention...</td>\n      <td>the author is pissed at &lt;user&gt; for having a g...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the author hates working late from home.</td>\n      <td>the author hates having to work late from home.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>your anxiety is not cured when someone says \"d...</td>\n      <td>the author is pissed at &lt;user&gt; for not fixing...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the author is pissed to watch a full train lea...</td>\n      <td>the author is pissed at &lt;user&gt; for having to ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the author doesn't find such notifications fro...</td>\n      <td>the author is pissed at &lt;user&gt; for not gettin...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>347</th>\n      <td>it isn't a cool week if it's 100 degrees.</td>\n      <td>it's very annoying when you're being sarcastic.</td>\n    </tr>\n    <tr>\n      <th>348</th>\n      <td>she's exactly like her dad, both are making si...</td>\n      <td>the author had fun with his mom.</td>\n    </tr>\n    <tr>\n      <th>349</th>\n      <td>the author is disappointed with this eclipse s...</td>\n      <td>this eclipse isn't even a good idea.</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>&lt;user&gt; app radar isn't right on target.</td>\n      <td>the author's disappointed with the app.</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>the author doesn't like to kick off her start ...</td>\n      <td>the author doesn't want to take a good way to...</td>\n    </tr>\n  </tbody>\n</table>\n<p>352 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"path_to_test_ocr_df = '/kaggle/working/final_outputs'\ntest_ocr_df = pd.read_csv(path_to_test_ocr_df, sep=\"\\t\", header=None)\n# columns, assign 4 column names\ntest_ocr_df.columns = ['pid', 'caption', 'source', 'reference'] \n\n# predictions_ocr = predictions[predictions['pid'].isin(test_ocr_df['pid'])]\npredictions.columns = ['reference', 'hypothesis']\n\n# Convert the 'reference' and 'hypothesis' columns to lists directly\ny_true = predictions['reference'].tolist()\ny_pred = predictions['hypothesis'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:56:17.055485Z","iopub.execute_input":"2024-09-29T13:56:17.056371Z","iopub.status.idle":"2024-09-29T13:56:17.070125Z","shell.execute_reply.started":"2024-09-29T13:56:17.056318Z","shell.execute_reply":"2024-09-29T13:56:17.069150Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"#predictions_ocr.to_csv(\"path to save predictions_test_ocr.tsv\",\n#                      sep='\\t', index=False, header=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T11:49:58.223557Z","iopub.status.idle":"2024-09-29T11:49:58.223885Z","shell.execute_reply.started":"2024-09-29T11:49:58.223719Z","shell.execute_reply":"2024-09-29T11:49:58.223735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path_to_test_non_ocr_df = 'Enter path to the test_set_non_ocr.tsv file to compute evaluation scores'\n# test_non_ocr_df = pd.read_csv(path_to_test_non_ocr_df, sep=\"\\t\", header=None)\n# test_non_ocr_df.columns = ['pid', 'source', 'reference']\n\n# predictions_non_ocr = predictions[predictions['pid'].isin(test_non_ocr_df['pid'])]\n# y_true = predictions_non_ocr.reference.tolist()\n# y_pred = predictions_non_ocr.hypothesis.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:56:13.783273Z","iopub.execute_input":"2024-09-29T13:56:13.784096Z","iopub.status.idle":"2024-09-29T13:56:13.788333Z","shell.execute_reply.started":"2024-09-29T13:56:13.784040Z","shell.execute_reply":"2024-09-29T13:56:13.787311Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"# y_pred","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:54:39.338864Z","iopub.execute_input":"2024-09-29T13:54:39.339362Z","iopub.status.idle":"2024-09-29T13:54:39.344009Z","shell.execute_reply.started":"2024-09-29T13:54:39.339319Z","shell.execute_reply":"2024-09-29T13:54:39.342938Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"#predictions_non_ocr.to_csv(\"path to save predictions_test_non_ocr.tsv\",\n#                          sep='\\t', index=False, header=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T11:49:58.227473Z","iopub.status.idle":"2024-09-29T11:49:58.227806Z","shell.execute_reply.started":"2024-09-29T11:49:58.227639Z","shell.execute_reply":"2024-09-29T11:49:58.227656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import nltk\n# from nltk.translate.bleu_score import sentence_bleu\n# from rouge import Rouge\n# from nltk.translate.meteor_score import meteor_score\n# from bert_score import score\n# from nltk.tokenize import word_tokenize\n\n# # Ensure you have the necessary NLTK data\n# nltk.download('punkt')\n# nltk.download('wordnet')\n\n# def preprocess(text):\n#     return word_tokenize(text.lower())\n\n# def calculate_metrics(y_true, y_pred):\n#     bleu_scores = []\n#     rouge_scores = []\n#     meteor_scores = []\n#     bert_scores = {'precision': [], 'recall': [], 'f1': []}\n    \n#     rouge = Rouge()\n    \n#     for true, pred in zip(y_true, y_pred):\n#         # Preprocess the texts\n#         true_tokens = preprocess(true)\n#         pred_tokens = preprocess(pred)\n        \n#         # BLEU\n#         bleu_scores.append(sentence_bleu([true_tokens], pred_tokens))\n        \n#         # ROUGE\n#         rouge_score = rouge.get_scores(pred, true)[0]\n#         rouge_scores.append(rouge_score['rouge-l']['f'])\n        \n#         # METEOR\n#         meteor_scores.append(meteor_score([true_tokens], pred_tokens))\n        \n#         # BERTScore\n#         p, r, f1 = score([pred], [true], lang=\"en\", verbose=False)\n#         bert_scores['precision'].append(p.item())\n#         bert_scores['recall'].append(r.item())\n#         bert_scores['f1'].append(f1.item())\n    \n#     return {\n#         'BLEU': sum(bleu_scores) / len(bleu_scores),\n#         'ROUGE-L': sum(rouge_scores) / len(rouge_scores),\n#         'METEOR': sum(meteor_scores) / len(meteor_scores),\n#         'BERTScore': {\n#             'Precision': sum(bert_scores['precision']) / len(bert_scores['precision']),\n#             'Recall': sum(bert_scores['recall']) / len(bert_scores['recall']),\n#             'F1': sum(bert_scores['f1']) / len(bert_scores['f1'])\n#         }\n#     }\n\n\n\n# results = calculate_metrics(y_true, y_pred)\n# print(results)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T13:57:56.365966Z","iopub.execute_input":"2024-09-29T13:57:56.366408Z","iopub.status.idle":"2024-09-29T13:57:56.372841Z","shell.execute_reply.started":"2024-09-29T13:57:56.366368Z","shell.execute_reply":"2024-09-29T13:57:56.371863Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install sacrebleu\n# !!pip install -U nltk\n# !pip install bert-score\n# !pip install rouge\n# !pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:00:14.121076Z","iopub.execute_input":"2024-09-29T14:00:14.121542Z","iopub.status.idle":"2024-09-29T14:00:14.126560Z","shell.execute_reply.started":"2024-09-29T14:00:14.121506Z","shell.execute_reply":"2024-09-29T14:00:14.125512Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"import evaluate\nfrom nltk.tokenize import sent_tokenize","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:00:22.566681Z","iopub.execute_input":"2024-09-29T14:00:22.567468Z","iopub.status.idle":"2024-09-29T14:00:22.690438Z","shell.execute_reply.started":"2024-09-29T14:00:22.567425Z","shell.execute_reply":"2024-09-29T14:00:22.689625Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"rouge_score = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:00:41.068122Z","iopub.execute_input":"2024-09-29T14:00:41.068937Z","iopub.status.idle":"2024-09-29T14:00:41.795169Z","shell.execute_reply.started":"2024-09-29T14:00:41.068897Z","shell.execute_reply":"2024-09-29T14:00:41.794417Z"},"trusted":true},"execution_count":89,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a6dbad85e82445185aa31b637b94d2f"}},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom statistics import mean\n\ndef compute_rouge_score(generated, reference):\n    # Add '\\n' to each line before sending it to ROUGE\n    generated_with_newlines = [\"\\n\".join(sent_tokenize(s.strip())) for s in generated]\n    reference_with_newlines = [\"\\n\".join(sent_tokenize(s.strip())) for s in reference]\n    \n    return rouge_score.compute(\n        predictions=generated_with_newlines,\n        references=reference_with_newlines,\n        use_stemmer=True,\n    )\n\n# Initialize empty lists to store the ROUGE scores\nrouge_1_scores = []\nrouge_2_scores = []\nrouge_l_scores = []\n\ntotal = len(y_pred)  # Total number of predictions\n\n# Use a single tqdm progress bar\nwith tqdm(total=total, position=0, leave=True, desc=\"Computing ROUGE scores\") as pbar:\n    for i in range(total):\n        # Compute the ROUGE score for each pair\n        score = compute_rouge_score([y_pred[i]], [y_true[i]])\n        \n        # Append individual ROUGE scores directly to their respective lists\n        rouge_1_scores.append(score['rouge1'])  # Assuming score['rouge1'] is a float\n        rouge_2_scores.append(score['rouge2'])  # Assuming score['rouge2'] is a float\n        rouge_l_scores.append(score['rougeL'])   # Assuming score['rougeL'] is a float\n        \n        # Update the progress bar\n        pbar.update(1)\n\n# Compute the average of each ROUGE score\navg_rouge_1 = mean(rouge_1_scores)\navg_rouge_2 = mean(rouge_2_scores)\navg_rouge_l = mean(rouge_l_scores)\n\n# Print the final average ROUGE scores\nprint(f\"Average ROUGE-1 F1 Score: {avg_rouge_1:.4f}\")\nprint(f\"Average ROUGE-2 F1 Score: {avg_rouge_2:.4f}\")\nprint(f\"Average ROUGE-L F1 Score: {avg_rouge_l:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:11:41.101393Z","iopub.execute_input":"2024-09-29T14:11:41.101811Z","iopub.status.idle":"2024-09-29T14:12:50.044486Z","shell.execute_reply.started":"2024-09-29T14:11:41.101770Z","shell.execute_reply":"2024-09-29T14:12:50.043579Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stderr","text":"Computing ROUGE scores: 100%|██████████| 352/352 [01:08<00:00,  5.11it/s]","output_type":"stream"},{"name":"stdout","text":"Average ROUGE-1 F1 Score: 0.2717\nAverage ROUGE-2 F1 Score: 0.1216\nAverage ROUGE-L F1 Score: 0.2466\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nfrom tqdm import tqdm\nfrom statistics import mean\n\n# Load the METEOR evaluator\nmeteor = evaluate.load('meteor')\n\n# Example predictions and references\npredictions = y_pred\nreferences = y_true\n\n# Initialize an empty list to store the METEOR scores\nmeteor_scores = []\n\ntotal = len(predictions)  # Total number of predictions\n\n# Use a single tqdm progress bar\nwith tqdm(total=total, position=0, leave=True, desc=\"Computing METEOR scores\") as pbar:\n    for i in range(total):\n        # Compute the METEOR score for each prediction and reference pair\n        result = meteor.compute(predictions=[predictions[i]], references=[references[i]])\n        \n        # Append the METEOR score to the list\n        meteor_scores.append(result['meteor'])  # Assuming result['meteor'] is a float\n        \n        # Update the progress bar\n        pbar.update(1)\n\n# Compute the average METEOR score\navg_meteor = mean(meteor_scores)\n\n# Print the final average METEOR score\nprint(f\"Average METEOR Score: {avg_meteor:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:13:21.881078Z","iopub.execute_input":"2024-09-29T14:13:21.882044Z","iopub.status.idle":"2024-09-29T14:13:27.413290Z","shell.execute_reply.started":"2024-09-29T14:13:21.882000Z","shell.execute_reply":"2024-09-29T14:13:27.412391Z"},"trusted":true},"execution_count":101,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b8a6b22e74490ebb36db60bdd945f2"}},"metadata":{}},{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"Computing METEOR scores: 100%|██████████| 352/352 [00:04<00:00, 75.32it/s] ","output_type":"stream"},{"name":"stdout","text":"Average METEOR Score: 0.2685\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nfrom tqdm import tqdm\nfrom statistics import mean\n\n# Load the BLEU evaluator\nbleu = evaluate.load(\"bleu\")\n\n\n# Initialize an empty list to store the BLEU scores\nbleu_scores = []\n\ntotal = len(predictions)  # Total number of predictions\n\n# Use a single tqdm progress bar\nwith tqdm(total=total, position=0, leave=True, desc=\"Computing BLEU scores\") as pbar:\n    for i in range(total):\n        # Compute the BLEU score for each prediction and reference pair\n        result = bleu.compute(predictions=[predictions[i]], references=[references[i]])\n        \n        # Append the BLEU score to the list\n        bleu_scores.append(result['bleu'])  # Assuming result['bleu'] is a float\n        \n        # Update the progress bar\n        pbar.update(1)\n\n# Compute the average BLEU score\navg_bleu = mean(bleu_scores)\n\n# Print the final average BLEU score\nprint(f\"Average BLEU Score: {avg_bleu:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:15:17.526098Z","iopub.execute_input":"2024-09-29T14:15:17.527116Z","iopub.status.idle":"2024-09-29T14:15:20.485379Z","shell.execute_reply.started":"2024-09-29T14:15:17.527047Z","shell.execute_reply":"2024-09-29T14:15:20.484463Z"},"trusted":true},"execution_count":102,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64bffc2324604a679306da620ee5468f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa69560b320d43bcb66ecd6b80da508f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a87b9f4163854d32a86d26c5f19a8b0a"}},"metadata":{}},{"name":"stderr","text":"Computing BLEU scores: 100%|██████████| 352/352 [00:01<00:00, 202.14it/s]","output_type":"stream"},{"name":"stdout","text":"Average BLEU Score: 0.0541\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"from evaluate import load\nfrom tqdm import tqdm\nfrom statistics import mean\n\n# Load the BERTScore evaluator\nbertscore = load(\"bertscore\")\n\n\n\n# Initialize lists to store the BERT scores\nf1_scores = []\n\ntotal = len(predictions)  # Total number of predictions\n\n# Use a single tqdm progress bar\nwith tqdm(total=total, position=0, leave=True, desc=\"Computing BERTScores\") as pbar:\n    for i in range(total):\n        # Compute the BERTScore for each prediction and reference pair\n        result = bertscore.compute(predictions=[predictions[i]], references=[references[i]], model_type=\"distilbert-base-uncased\")\n        \n        # Append the F1 score to the list\n        f1_scores.append(result['f1'][0])  # Assuming result['f1'] is a list with the first element being the score\n        \n        # Update the progress bar\n        pbar.update(1)\n\n# Compute the average BERT F1 score\navg_f1 = mean(f1_scores)\n\n# Print the final average BERT F1 score\nprint(f\"Average BERT F1 Score: {avg_f1:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:17:52.334373Z","iopub.execute_input":"2024-09-29T14:17:52.335095Z","iopub.status.idle":"2024-09-29T14:18:05.243042Z","shell.execute_reply.started":"2024-09-29T14:17:52.335041Z","shell.execute_reply":"2024-09-29T14:18:05.241990Z"},"trusted":true},"execution_count":107,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6af686e055194020b2135b094ff06777"}},"metadata":{}},{"name":"stderr","text":"Computing BERTScores:   0%|          | 0/352 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5172f758a594a608023a364343c429b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e985e98758e4df898637bc2c3feb611"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8396b89bc6440b85fe21b56af898fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c3c8208c2924490a18363217a62d0c1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3da71c6b2c04c778cbed18774b2abef"}},"metadata":{}},{"name":"stderr","text":"Computing BERTScores: 100%|██████████| 352/352 [00:12<00:00, 28.64it/s]","output_type":"stream"},{"name":"stdout","text":"Average BERT F1 Score: 0.7831\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(predictions[:3])\nprint(references[:3])","metadata":{"execution":{"iopub.status.busy":"2024-09-29T14:16:07.677686Z","iopub.execute_input":"2024-09-29T14:16:07.678121Z","iopub.status.idle":"2024-09-29T14:16:07.683324Z","shell.execute_reply.started":"2024-09-29T14:16:07.678060Z","shell.execute_reply":"2024-09-29T14:16:07.682308Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"[' the author is pissed at <user> for having a good design.', ' the author hates having to work late from home.', ' the author is pissed at <user> for not fixing their half empty glass.']\n['the author hates the design of this convention center, it makes him dizzy.', 'the author hates working late from home.', 'your anxiety is not cured when someone says \"don\\'t be anxious\".']\n","output_type":"stream"}]}]}